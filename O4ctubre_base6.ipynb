{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Banco de datos\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAMBIOS: \n",
    "\n",
    "#Cambio 1\n",
    "# se añadela variable mc_st en la ceda de parámetros de usuario, esta nos permite introducir el número de clusteres que deseamos crear una vez que se pueda analizar la stm.\n",
    "\n",
    "#Cambio 2:\n",
    "# Se agrega la cadena= base2 para identificar más facilmente los archivos de tiempo que se generen en esta versión.\n",
    "# De la biblioteca timeit se importa default_timer como timer\n",
    "# Se crea un data frame para guardar los tiempos que lleva cada proceso y saber en cuál tarda más.\n",
    "\n",
    "#Cambio 3:\n",
    "# Se eliminan las siguientes funciones: matrix_similarity_clusters y values\n",
    "# Se crea la funcion g_h_o_s que reemplaza a las funciones eliminadas\n",
    "\n",
    "# Cambio 4: \n",
    "# Ya no se mide el tiempo de la matriz GHOS porque ya no se hace.\n",
    "# Se miden los tiempos en la STM para ver dónde se tarda más.\n",
    "# Se tarda más en la función Analysis.\n",
    "# Se miden los tiempos dentro de la función de Analysis para saber donde se tarda más.\n",
    "# Se tarda más en A6\n",
    "\n",
    "# Cambio 5 \n",
    "# La siguiente línea se cambia ya que el método de append está obsoleto y será removido en futuras versiones. Este:\n",
    "# globals()['MC_'+str(winning_class)+'_'+str(winning_cluster)] = globals()['MC_'+str(winning_class)+'_'+str(winning_cluster)].append(X_test)\n",
    "# Por este: globals()['MC_'+str(winning_class)+'_'+str(winning_cluster)] = pd.concat((globals()['MC_'+str(winning_class)+'_'+str(winning_cluster)], X_test), axis = 0)\n",
    "\n",
    "# short_classes = short_classes.append(y_test.to_frame())  -- short_classes = pd.concat((short_classes, y_test.to_frame()), axis = 0)\n",
    "# short_term_memory = short_term_memory.append(X_test) -- short_term_memory = pd.concat((short_term_memory, X_test), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "# Bibliotecas para hacer clustering\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from statistics import mean \n",
    "from datetime import datetime #Ayuda a contar el tiempo de análisis en la ventana\n",
    "\n",
    "# import collections\n",
    "from itertools import groupby\n",
    "# importar un \"cronómetro\"\n",
    "from timeit import default_timer as timer\n",
    "# Para mostrar barra de progreso:\n",
    "#!pip install tqdm -q # Este ya esta instalado \n",
    "import time\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S = pd.read_csv('C:/Users/Karen Pamela/OneDrive - Instituto Politecnico Nacional/TESIS Karen/Bancos/kdd_recurrent_sm_nor_nep.csv')\n",
    "S = pd.read_csv('C:/Users/Karen Pamela/OneDrive - Instituto Politecnico Nacional/TESIS Karen/Bancos/normal2000_smurf2000_neptune.csv')\n",
    "\n",
    "cadena = 'base6_recurrent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>atrib1</th>\n",
       "      <th>atrib2</th>\n",
       "      <th>atrib3</th>\n",
       "      <th>atrib4</th>\n",
       "      <th>atrib5</th>\n",
       "      <th>atrib6</th>\n",
       "      <th>atrib7</th>\n",
       "      <th>atrib8</th>\n",
       "      <th>atrib9</th>\n",
       "      <th>...</th>\n",
       "      <th>atrib33</th>\n",
       "      <th>atrib34</th>\n",
       "      <th>atrib35</th>\n",
       "      <th>atrib36</th>\n",
       "      <th>atrib37</th>\n",
       "      <th>atrib38</th>\n",
       "      <th>atrib39</th>\n",
       "      <th>atrib40</th>\n",
       "      <th>atrib41</th>\n",
       "      <th>clase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>256368</td>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>ecr_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>453300</td>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>domain_u</td>\n",
       "      <td>SF</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256244</td>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>ecr_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>453038</td>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>domain_u</td>\n",
       "      <td>SF</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256453</td>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>ecr_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35995</th>\n",
       "      <td>252105</td>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>ecr_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35996</th>\n",
       "      <td>164573</td>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>ecr_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35997</th>\n",
       "      <td>139950</td>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>ecr_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35998</th>\n",
       "      <td>456598</td>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>326</td>\n",
       "      <td>849</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35999</th>\n",
       "      <td>8782</td>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>ecr_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36000 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  atrib1 atrib2    atrib3 atrib4  atrib5  atrib6  atrib7  \\\n",
       "0          256368       0   icmp     ecr_i     SF    1032       0       0   \n",
       "1          453300       0    udp  domain_u     SF      46      46       0   \n",
       "2          256244       0   icmp     ecr_i     SF    1032       0       0   \n",
       "3          453038       0    udp  domain_u     SF      42      42       0   \n",
       "4          256453       0   icmp     ecr_i     SF    1032       0       0   \n",
       "...           ...     ...    ...       ...    ...     ...     ...     ...   \n",
       "35995      252105       0   icmp     ecr_i     SF    1032       0       0   \n",
       "35996      164573       0   icmp     ecr_i     SF    1032       0       0   \n",
       "35997      139950       0   icmp     ecr_i     SF    1032       0       0   \n",
       "35998      456598       0    tcp      http     SF     326     849       0   \n",
       "35999        8782       0   icmp     ecr_i     SF    1032       0       0   \n",
       "\n",
       "       atrib8  atrib9  ...  atrib33  atrib34  atrib35  atrib36  atrib37  \\\n",
       "0           0       0  ...      255      1.0      0.0     1.00     0.00   \n",
       "1           0       0  ...      255      1.0      0.0     0.01     0.00   \n",
       "2           0       0  ...      255      1.0      0.0     1.00     0.00   \n",
       "3           0       0  ...      255      1.0      0.0     0.01     0.00   \n",
       "4           0       0  ...      255      1.0      0.0     1.00     0.00   \n",
       "...       ...     ...  ...      ...      ...      ...      ...      ...   \n",
       "35995       0       0  ...      255      1.0      0.0     1.00     0.00   \n",
       "35996       0       0  ...      255      1.0      0.0     1.00     0.00   \n",
       "35997       0       0  ...      255      1.0      0.0     1.00     0.00   \n",
       "35998       0       0  ...      255      1.0      0.0     0.01     0.02   \n",
       "35999       0       0  ...      255      1.0      0.0     1.00     0.00   \n",
       "\n",
       "       atrib38  atrib39  atrib40  atrib41    clase  \n",
       "0          0.0      0.0      0.0      0.0   smurf.  \n",
       "1          0.0      0.0      0.0      0.0  normal.  \n",
       "2          0.0      0.0      0.0      0.0   smurf.  \n",
       "3          0.0      0.0      0.0      0.0  normal.  \n",
       "4          0.0      0.0      0.0      0.0   smurf.  \n",
       "...        ...      ...      ...      ...      ...  \n",
       "35995      0.0      0.0      0.0      0.0   smurf.  \n",
       "35996      0.0      0.0      0.0      0.0   smurf.  \n",
       "35997      0.0      0.0      0.0      0.0   smurf.  \n",
       "35998      0.0      0.0      0.0      0.0  normal.  \n",
       "35999      0.0      0.0      0.0      0.0   smurf.  \n",
       "\n",
       "[36000 rows x 43 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# S = S[:round(len(S.index)*.1)]\n",
    "S = S[:36000] # 42000 #62000 # 9800\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parámetros de usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preguntar si la clase es numérica o categórica. \n",
    "# class_type lo usa preprocessing_label_coding function\n",
    "class_type = 'c' #input('Is the class numeric \"n\" or categorical \"c\"? ')\n",
    "# Introduce the instances for training the model\n",
    "InitNumber = 2000 #int(input(\"Introduce the InitNumber: \"))\n",
    "# Introduce the instances for the step window\n",
    "paso = 2000 #int(input(\"Window size: \"))\n",
    "# Introduce the instances for the short term memory\n",
    "n_elements_stm = 100 # 50 o 100\n",
    "# Introduce el numero de instancias para determinar si un cluster es válido\n",
    "n_representative = 20\n",
    "# Al Timestamp actual se le resta ventana_de_olvido para que instancias mas viejas\n",
    "# que esa diferencia se eliminen \n",
    "ventana_de_olvido = 2000 # más grande\n",
    "#paso * 0.5 # Ventana para no tener instancias viejas en el short_term_memory\n",
    "mc_stm = 10 # Número de clústeres que se harán en la stm\n",
    "opc_clasif = 1 #input(\"Como realizar la clasificación? \\n '1': si la clasificación es correcta se añade al mc, \\n '2': si cumple con un umbral de similitud se añade al mc\\n \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Modulos\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LABEL CODING\n",
    "\n",
    "The following function is for convert categoric attributes to label coding.\n",
    "\n",
    "Ordenate the dataframe as follows: label coding columns, numeric columns and CLASS columns.\n",
    "\n",
    "The function returns:\n",
    "- Preprocessed Dataframe.\n",
    "- Categoric columns names.\n",
    "- Numeric columns names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_label_coding(S, class_type):\n",
    "    \"\"\" Returns a preprocessed dataframe, for categoric attributes we use label\n",
    "        coding\n",
    "    INPUT: \n",
    "    - S: is the dataframe.\n",
    "    - class_type: is a letter c indicates categoric and n numeric.\n",
    "    OUTPUT:\n",
    "    - S1: is the preprocessed dataframe.\n",
    "    - num_col_names: names of the numeric attributes.\n",
    "    - cat_col_names: names of the categoric attributes.\n",
    "    \"\"\"\n",
    "    # Ask if the class is numeric or categoric.\n",
    "    # class_type = input('Is the class numeric \"n\" or categorical \"c\"?')\n",
    "    #Rename the last column\n",
    "    S.columns = [*S.columns[:-1], 'CLASS']\n",
    "\n",
    "    # Numeric columns\n",
    "    S_numeric = S.select_dtypes(exclude='object') #This is a dataframe only with numeric attributes\n",
    "    # Numeric colum names\n",
    "    num_col_names = list(S_numeric.columns)\n",
    "\n",
    "    # Categorical columns\n",
    "    S_categorical = S.select_dtypes(include='object')\n",
    "    # Numeric colum names\n",
    "    cat_col_names = list(S_categorical.columns)\n",
    "    # How many colums are categorical\n",
    "    len_categorical = len(cat_col_names)\n",
    "\n",
    "    # Label coding for categoric attributes\n",
    "    aux_data = pd.DataFrame(columns = cat_col_names)\n",
    "    # To do label coding:\n",
    "    # 1. Convert object type to category type\n",
    "    # 2 .cat.codes is for transform the categories to numbers\n",
    "    # +1 because the labels starts at 0 and NaN -1 but I want that Nan = 0\n",
    "    for i in range(len_categorical):\n",
    "        aux_data[cat_col_names[i]] = S_categorical[cat_col_names[i]].astype('category').cat.codes + 1\n",
    "\n",
    "    # S_categorical = label coding, zeros are replaced by NaN\n",
    "    S_categorical = aux_data.replace(0,np.NaN)\n",
    "\n",
    "    # ORDER my final dataframe with the following order:\n",
    "    # Categoric columns, Numeric colums, Class column\n",
    "    if class_type == 'c':\n",
    "        class_colum = S_categorical['CLASS'] \n",
    "        S_categorical.drop(\"CLASS\", axis=1, inplace=True) #Delete class_col\n",
    "        cat_col_names.pop() #Eliminate CLASS for this list\n",
    "        S1 = pd.concat([S_categorical,S_numeric,class_colum], axis=1) \n",
    "    else:\n",
    "        print('numeric')\n",
    "        A = S_numeric.shape\n",
    "        if A[1] == 1: #If numeric columns only has the class column\n",
    "            print(A[1])\n",
    "            class_colum = S_numeric['CLASS']\n",
    "            S1 = pd.concat([S_categorical,class_colum], axis=1) #Numeric columns will be empty\n",
    "            num_col_names.pop() #Eliminate CLASS for this list\n",
    "        else:\n",
    "            print(A[1])\n",
    "            class_colum = S_numeric['CLASS']\n",
    "            S_numeric.drop(\"CLASS\", axis=1, inplace=True)\n",
    "            S1 = pd.concat([S_categorical,S_numeric,class_colum], axis=1)\n",
    "            num_col_names.pop() #Eliminate CLASS for this list\n",
    "    #print(S1)\n",
    "    return S1, num_col_names, cat_col_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo inicial de entrenamiento\n",
    "\n",
    "\n",
    "This first phase is the initial training of the algorithm. A set of labeled instances will be needed to create the initial model. \n",
    "As suggestion the Initial Number will be 2,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - - - - - - - - - - MODEL TRAIN - - - - - - - - - -\n",
    "def create_model_train(S1, InitNumber):\n",
    "    \"\"\" Create the model train  \n",
    "    INPUT: \n",
    "    - S1\n",
    "    OUTPUT:\n",
    "    - Model Train\n",
    "    \"\"\"\n",
    "    # InitNumber = input(\"Introduce the InitNumber: \")\n",
    "    #InitNumber = int(InitNumber)\n",
    "\n",
    "    # Take the first window\n",
    "    model_train = S1[:InitNumber]\n",
    "    # Delete the model train instances from S1\n",
    "    aux_index = model_train.index.tolist()\n",
    "    S1 = S1.drop(aux_index)\n",
    "   \n",
    "    # To convert NaN to zeros\n",
    "    model_train = model_train.fillna(0)\n",
    "    return S1, model_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Microcluster information\n",
    "- Timestamp\n",
    "- Number of instances. Número de instancias\n",
    "- LS Linear sum. Suma lineal\n",
    "- SS Cuadratic sum. Suma cuadrática\n",
    "- Cj label of the class to which they belong. Etiqueta de la clase perteneciente\n",
    "- Centroid. Centroide\n",
    "- Radius. Radio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def microcluster_information(j, i):\n",
    "    \"\"\"Cálculo de la información del microcluster por 1era vez.\n",
    "    Para actualizaciones del mc se usa la función update\"\"\"   \n",
    "    # Time stamp\n",
    "    globals()['T_'+str(Cj[j])+'_'+str(i+1)] = globals()['MC_'+str(Cj[j])+'_'+str(i+1)].index[-1]\n",
    "    # Instance number\n",
    "    globals()['N_'+str(Cj[j])+'_'+str(i+1)] = len(globals()['MC_'+str(Cj[j])+'_'+str(i+1)].index)\n",
    "    # Lineal Sum\n",
    "    globals()['LS_'+str(Cj[j])+'_'+str(i+1)] = (globals()['MC_'+str(Cj[j])+'_'+str(i+1)].sum(axis=0)).drop(labels=['CLUSTER'])\n",
    "    # Square Sum\n",
    "    globals()['SS_'+str(Cj[j])+'_'+str(i+1)] = np.square(globals()['MC_'+str(Cj[j])+'_'+str(i+1)]).sum(axis=0).drop(labels=['CLUSTER'])\n",
    "    # Centroid LS/N\n",
    "    globals()['Centroid_MC_'+str(Cj[j])+'_'+str(i+1)] = globals()['LS_'+str(Cj[j])+'_'+str(i+1)] / globals()['N_'+str(Cj[j])+'_'+str(i+1)]\n",
    "    # Radius ( (SS/N) - pow(LS / N,2) ) ** 0.5\n",
    "    globals()['Radius_MC_'+str(Cj[j])+'_'+str(i+1)] = ((globals()['SS_'+str(Cj[j])+'_'+str(i+1)] / globals()['N_'+str(Cj[j])+'_'+str(i+1)]) - np.square(globals()['Centroid_MC_'+str(Cj[j])+'_'+str(i+1)])) ** 0.5\n",
    "    # Standard deviation\n",
    "    globals()['SD_'+str(Cj[j])+'_'+str(i+1)] = np.square(globals()['MC_'+str(Cj[j])+'_'+str(i+1)].drop(['CLUSTER'], axis=1) - globals()['Centroid_MC_'+str(Cj[j])+'_'+str(i+1)]).sum(axis=0)\n",
    "    # Sigma\n",
    "    globals()['sigma_'+str(Cj[j])+'_'+str(i+1)] = (globals()['SD_'+str(Cj[j])+'_'+str(i+1)] / globals()['N_'+str(Cj[j])+'_'+str(i+1)]) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GHOS SIMILARITY\n",
    "\n",
    "It recives the instance and returns the max value of similarity and says in which class and cluster is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_h_o_s(num_cluster, Cj, X_test, option):\n",
    "    \"\"\" This function applies the GHOS numeric similarity &\n",
    "        applies clostest clusters centroid 4 short term memory\n",
    "    INPUT: \n",
    "    - Cj: a list with class labels\n",
    "    - num_cluster: a list with the number of cluster for each class\n",
    "    - instance: the instance to compare\n",
    "    - option: 'similarity' means compute similarity function\n",
    "            : 'euclidean' means euclidean distance\n",
    "    OUTPUT: \n",
    "    - matrix (option 'similarity'): a dataframe with the clusters and classes and their similarity\n",
    "    - matrix (option 'euclidean'): a dataframe with the euclidean distances between one short term\n",
    "                         memory cluster and the microclusters centroids \n",
    "                         \n",
    "    \n",
    "    After similarity function, this function returns the cluster, class and max\n",
    "        value corresponding to the X_test\n",
    "    INPUT:\n",
    "    - matrix: is a matrix of whom we will get the max/min cluster/class\n",
    "              with classes as rows and cluster as columns\n",
    "    - option: 1 maximo means class max, cluster max, and max value\n",
    "              2 minimo means class min, cluster min, and min value\n",
    "    OUTPUT\n",
    "    - winning_class: The majority class \n",
    "    - winning_cluster: The majority cluster\n",
    "    - winning_value: The majority value\n",
    "    \"\"\"\n",
    "    instance = X_test\n",
    "    # print(\"y test: \" + str(int(y_test)))\n",
    "    # Matrix similarity clusters\n",
    "    k = 0 \n",
    "    columns = []   \n",
    "    class_ghos = []\n",
    "    index =[]\n",
    "    G = []\n",
    "    i_class = [] \n",
    "    i_clust = []\n",
    "    \n",
    "    if option == 'classification':\n",
    "        # Hacer un vector con los clusteres de cada clase\n",
    "        for k in range(len(Cj)): # Num of classes\n",
    "            for i in range(num_cluster[k]): # Num clusters\n",
    "                i_class.append('Clas_' + str(Cj[k]))\n",
    "                i_clust.append('Clust_' + str(i+1))\n",
    "                #index.append('Clas_' + str(Cj[k]) + '_Clust_' + str(i+1))\n",
    "                #print('Centroid_MC_'+str(Cj[k])+'_'+str(i+1))\n",
    "                #print('sigma_'+str(Cj[k])+'_'+str(i+1))\n",
    "                # - - - - GHOS numeric - - - -\n",
    "                GHOS = (abs( instance - globals()['Centroid_MC_'+str(Cj[k])+'_'+str(i+1)] ) <= globals()['sigma_'+str(Cj[k])+'_'+str(i+1)]).sum(axis=1)\n",
    "                G.append(GHOS.iloc[0])\n",
    "        #print(i_class)\n",
    "        #print(i_clust)\n",
    "        #print(G)\n",
    "        # Values winning_class, winning_cluster y ghos\n",
    "        # Quiero saber el máximo de la lista\n",
    "        ghos = max(G)\n",
    "        #print(\"GHOS: \" +str(ghos))\n",
    "        # Quiero saber la posición de ese valor máximo\n",
    "        max_index = G.index(ghos) \n",
    "        # Quiero saber la clase donde se encuentra este minimo\n",
    "        winning_class = int(i_class[max_index].replace('Clas_', ''))\n",
    "        #print(\"class: \" +str(winning_class))\n",
    "        # Cluster donde se encuentra el mínimo\n",
    "        winning_cluster = int(i_clust[max_index].replace('Clust_', ''))\n",
    "        #print(\"clust: \" +str(winning_cluster))\n",
    "        \n",
    "    else: #option == novel_detection\n",
    "        # Hacer un vector con los clusteres de cada clase\n",
    "        for k in range(len(Cj)): # Num of classes\n",
    "            for i in range(num_cluster[k]): # Num clusters\n",
    "                i_class.append('Clas_' + str(Cj[k]))\n",
    "                i_clust.append('Clust_' + str(i+1))\n",
    "                #index.append('Clas_' + str(Cj[k]) + '_Clust_' + str(i+1))\n",
    "                #print('Centroid_MC_'+str(Cj[k])+'_'+str(i+1))\n",
    "                #print('sigma_'+str(Cj[k])+'_'+str(i+1))\n",
    "                # - - - - GHOS numeric - - - -\n",
    "                GHOS = math.sqrt((np.square(instance - globals()['Centroid_MC_'+str(Cj[k])+'_'+str(i+1)])).sum())\n",
    "                G.append(GHOS)\n",
    "            ##print(i_class)\n",
    "            ##print(i_clust)\n",
    "            ##print(G)\n",
    "        # Quiero saber el mínimo de la lista\n",
    "        ghos = min(G) #ghos = b\n",
    "        ##print(\"GHOS: \" +str(ghos))\n",
    "        # Quiero saber la posición de ese valor máximo\n",
    "        min_index = G.index(ghos) \n",
    "        # print(min_index)\n",
    "        # Quiero saber la clase donde se encuentra este minimo\n",
    "        winning_class = int(i_class[min_index].replace('Clas_', ''))\n",
    "        # print(\"class: \" +str(winning_class))\n",
    "        # Cluster donde se encuentra el mínimo\n",
    "        winning_cluster = int(i_clust[min_index].replace('Clust_', ''))\n",
    "        # print(\"clust: \" +str(winning_cluster))\n",
    "\n",
    "    return winning_class, winning_cluster, ghos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MICROCLUSTER UPDATE\n",
    "\n",
    "After calculating the GHOS similarity value and the threshold comparision if that value is equal or bigger than the threshold, the instant test is added to its respective cluster. And it must to be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - - - - - - - - - - MICROCLUSTER UPDATE - - - - - - - - - -\n",
    "def update_microcluster(winning_class, winning_cluster, X_test):\n",
    "    \"\"\" This function refresh cluster statistics  \n",
    "    INPUT: \n",
    "    - winning_class: Class of the microcluster to be updated\n",
    "    - winning_cluster: Cluster of the microcluster to be updated\n",
    "    OUTPUT:\n",
    "    - Microcluster updated\n",
    "    \"\"\"\n",
    "    # Actualización del microcluster\n",
    "    # Time stamp\n",
    "    globals()['T_'+str(winning_class)+'_'+str(winning_cluster)] = X_test.index[-1]\n",
    "    # Instance number\n",
    "    globals()['N_'+str(winning_class)+'_'+str(winning_cluster)] = 1 + globals()['N_'+str(winning_class)+'_'+str(winning_cluster)]   \n",
    "    # Lineal Sum\n",
    "    globals()['LS_'+str(winning_class)+'_'+str(winning_cluster)] = X_test.iloc[0] + globals()['LS_'+str(winning_class)+'_'+str(winning_cluster)] \n",
    "    # Square Sum\n",
    "    globals()['SS_'+str(winning_class)+'_'+str(winning_cluster)] = np.square(X_test.iloc[0]) + globals()['SS_'+str(winning_class)+'_'+str(winning_cluster)]\n",
    "    # Centroid LS/N\n",
    "    globals()['Centroid_MC_'+str(winning_class)+'_'+str(winning_cluster)] = globals()['LS_'+str(winning_class)+'_'+str(winning_cluster)] / globals()['N_'+str(winning_class)+'_'+str(winning_cluster)]\n",
    "    # Radius ( (SS/N) - pow(LS / N,2) ) ** 0.5\n",
    "    globals()['Radius_MC_'+str(winning_class)+'_'+str(winning_cluster)] = ((globals()['SS_'+str(winning_class)+'_'+str(winning_cluster)] / globals()['N_'+str(winning_class)+'_'+str(winning_cluster)]) - np.square(globals()['Centroid_MC_'+str(winning_class)+'_'+str(winning_cluster)]))**0.5\n",
    "    # Standard deviation\n",
    "    globals()['SD_'+str(winning_class)+'_'+str(winning_cluster)] = np.square(X_test.iloc[0] - globals()['Centroid_MC_'+str(winning_class)+'_'+str(winning_cluster)]) + globals()['SD_'+str(winning_class)+'_'+str(winning_cluster)]\n",
    "    # Sigma\n",
    "    globals()['sigma_'+str(winning_class)+'_'+str(winning_cluster)] = (globals()['SD_'+str(winning_class)+'_'+str(winning_cluster)] / globals()['N_'+str(winning_class)+'_'+str(winning_cluster)]) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - - - - - - - - - - - - ¿CÓMO SE DESEA CLASIFICAR? - - - - - - - - - \n",
    "def clasification_original(winning_class, aciertos_clases, winning_cluster, y_test, X_test, \\\n",
    "    index, indice,n_ventana, ghos, clases, aciertos, c_v_det, short_classes, \\\n",
    "    short_term_memory, index_stm, clases_stm, ghos_stm, clasificados):\n",
    "    \n",
    "    \n",
    "    \"\"\" This function classify when the ghos coefficient determines a winning class and this winning class is equal to the real label\n",
    "    INPUT: \n",
    "    - winning_class: Class of the microcluster to be updated\n",
    "    - winning_cluster: Cluster of the microcluster to be updated\n",
    "    - y_test: the real class, the real label\n",
    "    - X_test: the instance that will be classified\n",
    "    - index\n",
    "    - indice\n",
    "    - n_ventana\n",
    "    - ghos\n",
    "    - clases\n",
    "    - aciertos\n",
    "    - c_v_det: Lista que almacena los patrones y sus clases que fueron clasificadas correctamente en la ventana.\n",
    "    - short_classes\n",
    "    - short_term_memory\n",
    "    - index_stm\n",
    "    - clases_stm\n",
    "    - ghos_stm\n",
    "    - aciertos\n",
    "    \n",
    "    OUTPUT:\n",
    "    - aciertos_clases\n",
    "    - update\n",
    "    - index\n",
    "    - clases\n",
    "    - aciertos\n",
    "    - c_v_det\n",
    "    - short_clases\n",
    "    - short_term_memory\n",
    "    - index_stm\n",
    "    - clases_stmn\n",
    "    - ghos_stm\n",
    "    - Microcluster updated\n",
    "    - aciertos\n",
    "    \"\"\"\n",
    "    if winning_class == int(y_test):\n",
    "        # Se crea una lista donde se almacene la clase que fue detectada correctamente\n",
    "        aciertos_clases.append(int(y_test))\n",
    "        #Se actualizan los MC\n",
    "        # Añade la instancia al final del microcluster\n",
    "        # La siguiente línea se cambia ya que el método de append está obsoleto y será removido en futuras versiones \n",
    "        # globals()['MC_'+str(winning_class)+'_'+str(winning_cluster)] = globals()['MC_'+str(winning_class)+'_'+str(winning_cluster)].append(X_test)\n",
    "        globals()['MC_'+str(winning_class)+'_'+str(winning_cluster)] = pd.concat((globals()['MC_'+str(winning_class)+'_'+str(winning_cluster)], X_test), axis = 0)\n",
    "        # Se actualizan las estadísticas\n",
    "        update_microcluster(winning_class, winning_cluster, X_test)\n",
    "        # Las siguientes 3 líneas son para llevar un registro de \n",
    "        # instancia, clase correcta y cual clase fue asignada.\n",
    "        index.append(indice)\n",
    "        new_clases = {\"Clase correcta\": int(y_test), \"Clasificado en\": winning_class, \"Ventana\": n_ventana, \"GHOS\": ghos,\"STM\":'no', 'Acierto':'verdaderos positivos'}\n",
    "        clases.append(new_clases)\n",
    "        aciertos = aciertos + 1\n",
    "        c_v_det.append(int(y_test))\n",
    "        clasificados = clasificados + 1 \n",
    "    else:\n",
    "        # Almacenar las clases correctas del short term memory\n",
    "        # La siguiente lpinea es cambiada de append por concat ya que append está obsoleto y será retirado en futuras versiones\n",
    "        # short_classes = short_classes.append(y_test.to_frame())\n",
    "        short_classes = pd.concat((short_classes, y_test.to_frame()), axis = 0)\n",
    "        # El short term memory\n",
    "        # La siguiente linea se cambia append por concate ya que apend en futuras versiones será removido.\n",
    "        # short_term_memory = short_term_memory.append(X_test)\n",
    "        short_term_memory = pd.concat((short_term_memory, X_test), axis = 0)\n",
    "        # Las siguientes 3 líneas son para llevar un registro de \n",
    "        # instancia, clase correcta y cual clase fue asignada.\n",
    "        new_clases_stm = {\"Clase correcta\": int(y_test), \"Clasificado en\":'STM', 'Ventana': n_ventana,\"GHOS\": ghos}\n",
    "        index_stm.append(indice) #Indices de las instancias en el short term memory   \n",
    "        clases_stm.append(new_clases_stm)\n",
    "        # Guardar el GHOS de cada instancia en el stm\n",
    "        ghos_stm.append(ghos)\n",
    "              \n",
    "    return aciertos_clases, index, clases, aciertos, c_v_det, \\\n",
    "    short_classes, short_term_memory, index_stm, clases_stm, ghos_stm, \\\n",
    "    clasificados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Short Term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - - - - - - - - - - CLUSTERS SHORT TERM MEMORY - - - - - - - - - -\n",
    "def clusters_stm(short_term_memory, mc_stm):\n",
    "    \"\"\" Returns the clusters obteined of short term memory  \n",
    "    INPUT: \n",
    "    - short term memory: data set of the instances belonging to short term memory\n",
    "    OUTPUT:\n",
    "    - Clusters: Is the same dataset as short term memory only with the difference of adding a\n",
    "      column wich indicates the number of what cluster of whats belongs that instance.\n",
    "    \"\"\"\n",
    "    n_clusters_stm = []\n",
    "    #n_clusters_stm.append(int(input(\"Introduce number of clusters: \")))\n",
    "    n_clusters_stm.append(mc_stm) ###PARÁMETRO QUE CAMBIA\n",
    "    kmeans_stm = KMeans(n_clusters = n_clusters_stm[-1], random_state=0).fit(short_term_memory) ##Apply k-means clustering\n",
    "    centroides = kmeans_stm.cluster_centers_\n",
    "    labels2 = pd.Series(kmeans_stm.labels_ + 1)\n",
    "    # Ese array lo pasamos a forma de Dataframe\n",
    "    labels2 = labels2.to_frame()\n",
    "    # Para poderlo concatenar al model train tenemos que hacer que los índices de las instancias cuadren\n",
    "    labels2.index = short_term_memory.index\n",
    "    # Renombramos a la columna con la palabra CLUSTER\n",
    "    labels2.rename( columns={0:'CLUSTER'}, inplace=True )\n",
    "    Clusters = pd.concat([short_term_memory,labels2], axis=1)\n",
    "    return Clusters, n_clusters_stm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_extension(Cj, clase_cercana, num_cluster, ShortCluster, aux_index_sc, \\\n",
    "    short_classes, aciertos_stm, index_right_stm, clasif_right_stm,\\\n",
    "    index_wrong_stm, clasif_wrong_stm, cluster_cercano, instancias_stm, n_ventana,\\\n",
    "    n_cluster_stm, N, T):\n",
    "    \"\"\" This function create a cluster in a new class  \n",
    "    INPUT: \n",
    "    - Cj: es una lista que contiene las etiquetas de las clases que se han registrado.\n",
    "    - clase_cercana = La clase donde está la menor distancia de su centroide al \n",
    "                      centroide del n uevo microcluster.\n",
    "    - num_cluster: es una lista que me indica cuantos clusters hay por clase, se debe \n",
    "                   de leer con Cj para entenderlo.\n",
    "    - ShortCluster: el cluster a integrar como extensión de una clase. \n",
    "    - aux_index_sc: contiene los índices de las instancias de ese cluster obtenido del\n",
    "                    Short Term Memory.\n",
    "    - aciertos_stm: contador de instancias que son asignadas correctamente.\n",
    "    - short_classes = son las clases originales/correctas de las instancias que están en\n",
    "                      el Short Term Memory.\n",
    "    - index_right_stm: una lista que va acumulando los indices de las instancias en la\n",
    "                       stm que fueron asignadas correctamente.\n",
    "    - clasif_right_stm = es un diccionario que almacena clases correctas, asignadas y el\n",
    "                         ghos de las instancias asignadas.\n",
    "    - index_wrong_stm = una lista que va acumulando los indices de las instancias en la\n",
    "                       stm que NO fueron asignadas correctamente.\n",
    "    - clasif_wrong_stm = es un diccionario que almacena clases correctas, asignadas y el\n",
    "                         ghos de las instancias NO asignadas.\n",
    "    - n_ventana = es un entero que especifica que ventana se está analizando.\n",
    "\n",
    "    OUTPUT:\n",
    "    - Cj, num_cluster, aciertos_stm, index_right_stm, clasif_right_stm, index_wrong_stm, \n",
    "      clasif_wrong_stm\n",
    "   \"\"\"\n",
    "    # Se añade la extensión de clase    \n",
    "    idx_clase = pd.Index(clases_originales[aux_index_sc].tolist(), name ='CLASS')\n",
    "    idx_clase = idx_clase.value_counts() #Esto queda en forma de core series  2 100\n",
    "    idx_clase = idx_clase[idx_clase == idx_clase.max()].index[0]\n",
    "\n",
    "    clase_mayor_frecuencia = idx_clase # la clase original q:e más se repite\n",
    "    \n",
    "    # Se pregunta si la clase original con mayor repetición es igual a la calculada\n",
    "    if clase_mayor_frecuencia == clase_cercana:\n",
    "        print(\"La mayoría de los patrones son clase: \" +str(clase_mayor_frecuencia) + \". Y la clase cercana detectada fue: \" +str(clase_cercana))\n",
    "        print(\"Se añade esta extensión de clase.\")\n",
    "        class_index = Cj.index(clase_cercana)\n",
    "        num_cluster[class_index] = num_cluster[class_index] + 1\n",
    "        globals()['MC_'+str(Cj[class_index])+'_'+str(num_cluster[class_index])] = ShortCluster\n",
    "        \n",
    "        #Se calculan las estadísticas de este nuevo microcluster\n",
    "        microcluster_information(class_index, num_cluster[class_index]-1)\n",
    "        for j in range(len(aux_index_sc)):    \n",
    "            #Si la asignación fue correcta\n",
    "            if int(short_classes.loc[aux_index_sc[j]]) == clase_cercana:\n",
    "                aciertos_stm = aciertos_stm + 1\n",
    "                # Las siguientes 3 líneas son para llevar un registro de la asignación.\n",
    "                index_right_stm.append(aux_index_sc[j])\n",
    "                new_clases = {\"correct Class\": int(short_classes.loc[aux_index_sc[j]]), \"classified in\": 'MC_'+str(clase_cercana)+'_'+str(num_cluster[class_index]), \"GHOS\": instancias_stm.at[aux_index_sc[j], 'GHOS'], 'acierto':'asignada correctamente'}\n",
    "                clasif_right_stm.append(new_clases)\n",
    "                # new_clases = {\"correct Class\": int(short_classes.loc[aux_index_sc[j]]), \"classified in\": clase_cercana, \"GHOS\": instancias_stm.at[aux_index_sc[j]], 'acierto':'Bien'}\n",
    "            else: # Si la asignacion fue incorrecta:\n",
    "                # Las siguientes 3 líneas son para llevar un registro de la asignación.\n",
    "                print(\"Se descarta la extensión de clase\")\n",
    "                index_wrong_stm.append(aux_index_sc[j])\n",
    "                new_clases = {\"Clase_correcta\": int(short_classes.loc[aux_index_sc[j]]), \\\n",
    "                \"Clasificado en\": 'MC_'+str(clase_cercana)+'_'+str(num_cluster[class_index]),\\\n",
    "                \"GHOS\": instancias_stm.at[aux_index_sc[j], 'GHOS'], \"STM\":'YES', \\\n",
    "                'Acierto':'asignada incorrectamente', 'Ventana':n_ventana}\n",
    "                clasif_wrong_stm.append(new_clases)\n",
    "\n",
    "    else: # si no coincide, hay error y no se añade al modelo\n",
    "        print(\"La clase cercana es : \" + str(clase_cercana) + \", pero la clase con mayor repetición es: \" + str(clase_mayor_frecuencia))\n",
    "        print(\"Se descarta esta extensión\")\n",
    "        \n",
    "        new_emerging_clases = {\"Ventana\": n_ventana, \"Cluster STM\": n_cluster_stm, 'clase original': clase_mayor_frecuencia,\\\n",
    "        'clase propuesta': clase_cercana, 'error': \"extension\", 'instancias': N, \"T\": T}\n",
    "        no_emerging.append(new_emerging_clases)            \n",
    "            \n",
    "    short_classes = short_classes.drop(aux_index_sc)    \n",
    "    return Cj, num_cluster, aciertos_stm, index_right_stm, clasif_right_stm, index_wrong_stm, clasif_wrong_stm, short_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emerging_class(Cj, clases_originales, num_cluster, ShortCluster, aux_index_sc, short_classes, \\\n",
    "    aciertos_stm, index_right_stm, clasif_right_stm, index_wrong_stm, clasif_wrong_stm, \\\n",
    "    instancias_stm, n_ventana, n_cluster_stm, N, T):\n",
    "    \"\"\" This function create a cluster in a new class  \n",
    "    INPUT: \n",
    "    - Cj: es una lista que contiene las etiquetas de las clases que se han registrado.\n",
    "    - num_cluster: es una lista que me indica cuantos clusters hay por clase, \\\n",
    "                   se debe de leer con Cj para entenderlo.\n",
    "    - ShortCluster: el cluster a integrar en una nueva clase o extensión de una clase. \n",
    "    - aux_index_sc: contiene los índices de las instancias de ese cluster obtenido\\\n",
    "                    del Short Term Memory.\n",
    "    - short_classes = son las clases originales/correctas de las instancias que están en el\\\n",
    "                      Short Term Memory.\n",
    "    - aciertos_stm: una variable que va acumulando los aciertos que se tiene en el STM.\n",
    "    - index_right_stm: una lista que va acumulando los indices de las instancias en la\n",
    "                       stm que fueron asignadas correctamente.\n",
    "    - clasif_right_stm = es un diccionario que almacena clases correctas, asignadas y el\n",
    "                         ghos de las instancias asignadas.\n",
    "    - index_wrong_stm = una lista que va acumulando los indices de las instancias en la\n",
    "                       stm que NO fueron asignadas correctamente.\n",
    "    - clasif_wrong_stm = es un diccionario que almacena clases correctas, asignadas y el\n",
    "                         ghos de las instancias NO asignadas.\n",
    "    - instancias_stm\n",
    "    - n_ventana = es un entero que especifica la ventana que se está utilizando\n",
    "\n",
    "    OUTPUT:\n",
    "    - Cj, num_cluster, short_classes, aciertos_stm, index_right_stm, clasif_right_stm, \n",
    "      index_wrong_stm, clasif_wrong_stm\n",
    "    \"\"\"\n",
    "    # Se añade la nueva clase    \n",
    "    idx_clase = pd.Index(clases_originales[aux_index_sc].tolist(), name ='CLASS')\n",
    "    idx_clase = idx_clase.value_counts() #Esto queda en forma de core series  2 100\n",
    "    idx_clase = idx_clase[idx_clase == idx_clase.max()].index[0]\n",
    "\n",
    "    nueva_clase = idx_clase\n",
    "\n",
    "    # Se pregunta si el índice de la clase original ya había sido tratado en el modelo \n",
    "    if nueva_clase in Cj:  #Si es así, no intervendrá en el modelo\n",
    "        print(\"La clase \"+str(nueva_clase) + \" ya existía.\")\n",
    "\n",
    "        new_emerging_clases = {\"Ventana\": n_ventana, \"Cluster STM\": n_cluster_stm, 'clase original': nueva_clase,\\\n",
    "        'clase propuesta': 0, 'error': \"emergente\", 'instancias': N, 'T': T}\n",
    "        no_emerging.append(new_emerging_clases) \n",
    "\n",
    "    else: # Sí no es así, se crea el microcluster.\n",
    "        print(\"La nueva clase es: \" + str(nueva_clase))\n",
    "        # Al 'vector' Cj se le añade como último elemento la nueva clase\n",
    "        Cj.append(nueva_clase)\n",
    "\n",
    "        # Sería el primer microcluster de esa clase\n",
    "        num_cluster.append(1)\n",
    "\n",
    "        # Se crea el nuevo microcluster\n",
    "        globals()['MC_'+str(Cj[-1])+'_'+str(num_cluster[-1])] = ShortCluster\n",
    "\n",
    "        #microcluster_information(clase, clluster)\n",
    "        microcluster_information(len(Cj)-1, 0)\n",
    "\n",
    "        # El siguiente ciclo for es para visualizar en un dataframe instancia por instancia\n",
    "        # su clase original y el MC a la cual fue asignada\n",
    "        for j in range(len(aux_index_sc)):\n",
    "            # SABER NUMERO DE VENTANA, CLASE ASIGNADA\n",
    "            # NUMERO DE ELEMENTOS DE LAS CLASES CORRECTAS EN ESTE MICROCLUSTER  \n",
    "            # Si la asignación fue correcta\n",
    "            if int(short_classes.loc[aux_index_sc[j]]) == nueva_clase:\n",
    "                aciertos_stm = aciertos_stm + 1\n",
    "                # Las siguientes 3 líneas son para llevar un registro de la asignación.\n",
    "                index_right_stm.append(aux_index_sc[j])\n",
    "                new_clases = {\"correct Class\": int(short_classes.loc[aux_index_sc[j]]),\\\n",
    "                \"classified in\": 'MC_'+str(nueva_clase)+'_'+str(1), \"GHOS\": instancias_stm.at[aux_index_sc[j], 'GHOS'],\\\n",
    "                \"stm\":'YES', 'acierto':'Bien'}\n",
    "                clasif_right_stm.append(new_clases)\n",
    "\n",
    "            else: # Si la asignación fue incorrecta\n",
    "                ## ESCRIBIR NUMERO DE VENTANAS, CLASE QUE DETECTÓ\n",
    "                # Las siguientes 3 líneas son para llevar un registro de la asignación.\n",
    "                index_wrong_stm.append(aux_index_sc[j])\n",
    "                new_clases = {\"Clase_correcta\": int(short_classes.loc[aux_index_sc[j]]),\\\n",
    "                \"Clasificado en\": 'MC_'+str(nueva_clase)+'_'+str(1),\\\n",
    "                \"GHOS\": instancias_stm.at[aux_index_sc[j], 'GHOS'],\"STM\":'YES',\\\n",
    "                'Acierto':'asignado incorrectamente.',\n",
    "                'Ventana': n_ventana}\n",
    "                clasif_wrong_stm.append(new_clases) \n",
    "\n",
    "    # CONTAR LA FRECUENCIA DE CADA CLASE CORRECTA EN ESTE MICROCLUSTER\n",
    "\n",
    "    short_classes = short_classes.drop(aux_index_sc)\n",
    "    \n",
    "    return Cj, num_cluster, aciertos_stm, index_right_stm, clasif_right_stm,index_wrong_stm, clasif_wrong_stm, short_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_stm(short_term_memory, short_classes, Clusters, n_clusters_stm,\\\n",
    "    Cj, clases_originales, num_cluster, aciertos_stm,index_right_stm, clasif_right_stm, index_wrong_stm,\\\n",
    "    clasif_wrong_stm, instancias_stm, n_ventana):\n",
    "    \"\"\"Checa si un cluster es o no es válido.\n",
    "    Si es válido, hace la asignación como extensión de la clase o clase\n",
    "    emergente.\n",
    "    INPUT:\n",
    "    - short_term_memory: \n",
    "    - short_classes: son las clases originales/correctas de las instancias que están en\\\n",
    "                     el Short Term Memory.\n",
    "    - Clusters: Dataframe con las instancias clasificadas por clusters\n",
    "    - n_clusters_stm: Es una lista que contiene el número de clusters que deseamos tener\n",
    "                      de las isntancias del short term memory\n",
    "    - Cj: es una lista que contiene las etiquetas de las clases que se han registrado.\n",
    "    - num_cluster: es una lista que me indica cuantos clusters hay por clase, \\\n",
    "                   se debe de leer con Cj para entenderlo.\n",
    "    - aciertos_stm: una variable que va acumulando los aciertos que se tiene en el STM.\n",
    "    - index_right_stm: es una lista que contiene los índices de las instancias de la \n",
    "                       short term memory que fueron asignadas correctamente.                       \n",
    "    - clasif_right_stm: es un diccionario dentro de una lista que de cada instancia\n",
    "                        de la stm, asignadas correctamente me da información para \n",
    "                        visualizarla en un dataframe, la información que me proporciona\n",
    "                        es clase correcta, en cual se asignó y valor de GHOS. \n",
    "    - index_wrong_stm: cumple la misma función que index_right_stm pero con las instancias\n",
    "                       que fueron asignadas erroneamente.\n",
    "    - clasif_wrong_stm: cumple la misma función que index_right_stm pero con las instancias\n",
    "                       que fueron asignadas erroneamente.\n",
    "    - instancias_stm: Es el dataframe que da la información correcta y el valor de GHOS de\n",
    "                      todas las instancias que se fueron al STM.\n",
    "    - n_ventana:  es un entero que especifíaca el número de ventana que se está analizando\n",
    "    \n",
    "    OUTPUT:\n",
    "    - Cj, short_term_memory, num_cluster, ShortCluster,aux_index_sc, short_classes, aciertos_stm,\\\n",
    "    index_right_stm, clasif_right_stm,index_wrong_stm,clasif_wrong_stm\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Analysis\")\n",
    "    ## Tiempo de ejecución\n",
    "    \n",
    "    an_tot_stm = 0.0\n",
    "    an1_stm = 0.0\n",
    "    an_ini_stm = timer()\n",
    "    \n",
    "    for i in range(n_clusters_stm[-1]):\n",
    "        n_cluster_stm = i + 1\n",
    "        #Este es el cluster del short term memory a analizar\n",
    "        ShortCluster = Clusters[Clusters['CLUSTER']==i+1]\n",
    "        # Es cohesivo?\n",
    "        # Calcular Silhouette. Para ello debemos de tener el centroide del microcluster.\n",
    "        # Centroid LS/N\n",
    "        N = len(ShortCluster.index)\n",
    "        print(\"\\n El cluster \" + str(i+1) + \" tiene: \" + str(N) + \" instancias.\")\n",
    "        print('LS')\n",
    "        LS = (ShortCluster.sum(axis=0)).drop(labels=['CLUSTER'])\n",
    "        print('LS')\n",
    "        Centroid = LS / N\n",
    "        Silhouette = 0  \n",
    "        # - - - - - VALIDACION DEL CLUSTER - - - - - - - -     \n",
    "        # Se verifica si es representativo, si lo es, se verifica si es cohesivo (Silhouette)\n",
    "        # ...To identify if a cluster is cohesive, a modified silhouette coefficient will be used...\n",
    "        \n",
    "        # - - - - - - REPRESENTATIVO - - - - - - - - \n",
    "        if N >= n_representative: #Si es representativo entra a este for\n",
    "        # Silhouette = b-a / max(a,b)\n",
    "            clase_cercana, cluster_cercano, b = g_h_o_s(num_cluster, Cj, Centroid, 'novel_detection')\n",
    "        # a standar deviation of the distance between each instance of the new microcluster\n",
    "        # and the new microcluster centroid\n",
    "            a = []\n",
    "            for i in range(len(ShortCluster)):\n",
    "            # a es una lista que almacena las distancias euclideanas entre cada instancia de ese\n",
    "            # microcluster y el centroide.\n",
    "                a.append(np.linalg.norm(ShortCluster.iloc[[i]].drop(['CLUSTER'], axis=1) - Centroid))\n",
    "            # Ya obtenidas las distancias euclideanas calculamos la desviación estándar\n",
    "            # sqrt (((x_prom - x)**2 suma) / N )\n",
    "            a = math.sqrt(((mean(a) - a)**2).sum() / len(a))\n",
    "            ##  print(\"a: \" + str(a))\n",
    "            if max(b,a) != 0:\n",
    "                Silhouette = (b - a) / max(b, a)\n",
    "            # Verificar si el cluster es válido, significa que Silhouette > 0,\n",
    "            # si es representativo y válido: instancias se eliminan del short term memory\n",
    "                # print(\"Silhouette: \" + str(Silhouette))\n",
    "                # print(\"b = \" + str(b) + \". a = \" + str(a))\n",
    "            # - - - - - - - - - - - COHESIVO - - - - - -\n",
    "                if Silhouette > 0: # El cluster es válido\n",
    "                    aux_index_sc = ShortCluster.index.tolist()\n",
    "                # Borrar estas instancias del short term memory y también sus clases\n",
    "                    short_term_memory = short_term_memory.drop(aux_index_sc)\n",
    "                    # - - - - NOVELTY PROCESS - - - - \n",
    "                    # - - - - - - Threshold - - - - - -\n",
    "                    # T = la media de las distancias del centroide del microcluster de la clase \n",
    "                    # más cercana con respecto a los demás microclusters de esa clase\n",
    "                    # print(\"Cálculo de T\")\n",
    "                    Centroide_cercano = globals()['Centroid_MC_'+str(clase_cercana)+'_'+str(cluster_cercano)]\n",
    "                    # print(\"Distancia entre el Centroide_\"+ str(clase_cercana)+\"_\"+str(cluster_cercano) + \" con respecto a:\")\n",
    "                    T = []\n",
    "                    # print(\"La clase cercana es: \" + str(clase_cercana) + \" y el cluster cercano es: \" + str(cluster_cercano))\n",
    "                    class_index = Cj.index(clase_cercana) # class index guarda la posición de Cj donde está la clase más cercana\n",
    "                    # esta posición la busco en num_cluster para saber cuantos clusters hay en la clase más cercana \n",
    "                    for j in range(0, num_cluster[class_index]): # Modifiqué porque estaba malrange(0, cluster_cercano)\n",
    "                        i = j + 1\n",
    "                        if i != cluster_cercano: # Si el índice i coincide con cluster cercano no entra en esta sentencia porque\n",
    "                            # no debe calcular la distancia con respecto a él mismo\n",
    "                            #print(\"Se compara con clase: \"  + str(clase_cercana) + \", cluster: \"+ str(i))\n",
    "                            # la distancia se estaría compárando con respecto al mismo centroide \n",
    "                            T.append(np.linalg.norm(globals()['Centroid_MC_'+str(clase_cercana)+'_'+str(i)] - Centroide_cercano))\n",
    "                            # print(\"Centroide más cercano vs Centroide_\" + str(clase_cercana) + \"_\"+str(i+1))\n",
    "                    print(\"T antes del promedio: \" + str(T))\n",
    "                    if len(T) >= 1: #Significa que hay al menos 2 clusteres de esa clase\n",
    "                        print(\"T tiene más de un micro cluster en esa clase.\")\n",
    "                        T = sum(T)/len(T)\n",
    "                        print(\"T = \" + str(T))\n",
    "                    else: #Significa que solo hay un cluster de esa clase\n",
    "                        #Aquí \n",
    "                        print(\"T solo tiene 1 microcluster en esa clase, hay que recalcular\")\n",
    "                        # Se inicializa T = [] para hacer el promedio entre el \n",
    "                        # Centroide y sus instancias\n",
    "                        T = [] \n",
    "                        # for que recorre instancia por instancia del microcluster más cercano (mp).\n",
    "                        for i in range(len(globals()['MC_'+str(clase_cercana)+'_'+str(cluster_cercano)])):\n",
    "                            # T es una lista que almacena las distancia euclideanas\n",
    "                            # de cada instancia de mp con respecto al centroide mp  \n",
    "                            T.append( np.linalg.norm(globals()['MC_'+str(clase_cercana)+'_'+str(cluster_cercano)].iloc[[i]].drop(['CLUSTER'], axis=1) - globals()['Centroid_MC_'+str(clase_cercana)+'_'+str(cluster_cercano)]) )\n",
    "                        # Ya obtenidas las distancias euclideanas calculamos la desviación estándar\n",
    "                        # sqrt (((x_prom - x)**2 suma) / N )\n",
    "                        T = math.sqrt(((mean(T) - T)**2).sum() / len(T))\n",
    "                        print(\"T: \" + str(T))\n",
    "                    # ¿Existente o nueva clase?\n",
    "                    print(\"b: \" +str(b) + \", T: \" + str(T))\n",
    "                    # - - - - - - - EXTENSIÓN DE CLASE - - - - - - \n",
    "                    if b < T:  #El nuevo microcluster se considera una extensión de la clase\n",
    "                    #print(\"B: \" + str(b) + \", T: \" + str(T))\n",
    "                    #print(\"Clust cerc: \" +str(cluster_cercano) + \"clase cercana: \" + str(clase_cercana))\n",
    "                        print(\"EXTENSIÓN de clase\")\n",
    "                        Cj, num_cluster, aciertos_stm, index_right_stm, clasif_right_stm,\\\n",
    "                        index_wrong_stm, clasif_wrong_stm, short_classes = class_extension(Cj,\\\n",
    "                        clase_cercana, num_cluster, ShortCluster, aux_index_sc, short_classes,\\\n",
    "                        aciertos_stm, index_right_stm, clasif_right_stm, index_wrong_stm,\\\n",
    "                        clasif_wrong_stm, cluster_cercano, instancias_stm, n_ventana, n_cluster_stm,\\\n",
    "                        N, T)\n",
    "                        print(\"Así quedan las clases y sus respectivos clusters.\")\n",
    "                        print(Cj)\n",
    "                        print(num_cluster)\n",
    "                    # - - - - - - - NUEVA CLASE - - - - - - - - \n",
    "                    else: #El microcluster se considera una clase emergente\n",
    "                        print(\"Clase EMERGENTE\")\n",
    "                        \"\"\"\n",
    "                        Cj, num_cluster, aciertos_stm, index_right_stm, clasif_right_stm,\\\n",
    "                        index_wrong_stm,clasif_wrong_stm, short_classes = emerging_class(Cj,\\\n",
    "                        clases_originales, num_cluster, ShortCluster,aux_index_sc, short_classes,\\\n",
    "                        aciertos_stm, index_right_stm, clasif_right_stm,index_wrong_stm,clasif_wrong_stm,\\\n",
    "                        instancias_stm, n_ventana, n_cluster_stm, N, T)\n",
    "                        \"\"\"\n",
    "                        # Se añade la nueva clase    \n",
    "                        idx_clase = pd.Index(clases_originales[aux_index_sc].tolist(), name ='CLASS')\n",
    "                        idx_clase = idx_clase.value_counts() #Esto queda en forma de core series  2 100\n",
    "                        idx_clase = idx_clase[idx_clase == idx_clase.max()].index[0]\n",
    "\n",
    "                        nueva_clase = idx_clase\n",
    "\n",
    "                        # Se pregunta si el índice de la clase original ya había sido tratado en el modelo \n",
    "                        if nueva_clase in Cj:  #Si es así, no intervendrá en el modelo\n",
    "                            print(\"La clase \"+str(nueva_clase) + \" ya existía.\")\n",
    "\n",
    "                            new_emerging_clases = {\"Ventana\": n_ventana, \"Cluster STM\": n_cluster_stm, 'clase original': nueva_clase,\\\n",
    "                            'clase propuesta': 0, 'error': \"emergente\", 'instancias': N, 'T': T}\n",
    "                            no_emerging.append(new_emerging_clases) \n",
    "\n",
    "                        else: # Sí no es así, se crea el microcluster.\n",
    "                            print(\"La nueva clase es: \" + str(nueva_clase))\n",
    "                            # Al 'vector' Cj se le añade como último elemento la nueva clase\n",
    "                            Cj.append(nueva_clase)\n",
    "\n",
    "                            # Sería el primer microcluster de esa clase\n",
    "                            num_cluster.append(1)\n",
    "\n",
    "                            # Se crea el nuevo microcluster\n",
    "                            globals()['MC_'+str(Cj[-1])+'_'+str(num_cluster[-1])] = ShortCluster\n",
    "\n",
    "                            #microcluster_information(clase, clluster)\n",
    "                            microcluster_information(len(Cj)-1, 0)\n",
    "\n",
    "                            # El siguiente ciclo for es para visualizar en un dataframe instancia por instancia\n",
    "                            # su clase original y el MC a la cual fue asignada\n",
    "                            for j in range(len(aux_index_sc)):\n",
    "                                # SABER NUMERO DE VENTANA, CLASE ASIGNADA\n",
    "                                # NUMERO DE ELEMENTOS DE LAS CLASES CORRECTAS EN ESTE MICROCLUSTER  \n",
    "                                # Si la asignación fue correcta\n",
    "                                if int(short_classes.loc[aux_index_sc[j]]) == nueva_clase:\n",
    "                                    aciertos_stm = aciertos_stm + 1\n",
    "                                    # Las siguientes 3 líneas son para llevar un registro de la asignación.\n",
    "                                    index_right_stm.append(aux_index_sc[j])\n",
    "                                    new_clases = {\"correct Class\": int(short_classes.loc[aux_index_sc[j]]),\\\n",
    "                                    \"classified in\": 'MC_'+str(nueva_clase)+'_'+str(1), \"GHOS\": instancias_stm.at[aux_index_sc[j], 'GHOS'],\\\n",
    "                                    \"stm\":'YES', 'acierto':'Bien'}\n",
    "                                    clasif_right_stm.append(new_clases)\n",
    "\n",
    "                                else: # Si la asignación fue incorrecta\n",
    "                                    ## ESCRIBIR NUMERO DE VENTANAS, CLASE QUE DETECTÓ\n",
    "                                    # Las siguientes 3 líneas son para llevar un registro de la asignación.\n",
    "                                    index_wrong_stm.append(aux_index_sc[j])\n",
    "                                    new_clases = {\"Clase_correcta\": int(short_classes.loc[aux_index_sc[j]]),\\\n",
    "                                    \"Clasificado en\": 'MC_'+str(nueva_clase)+'_'+str(1),\\\n",
    "                                    \"GHOS\": instancias_stm.at[aux_index_sc[j], 'GHOS'],\"STM\":'YES',\\\n",
    "                                    'Acierto':'asignado incorrectamente.',\n",
    "                                    'Ventana': n_ventana}\n",
    "                                    clasif_wrong_stm.append(new_clases) \n",
    "\n",
    "                        # CONTAR LA FRECUENCIA DE CADA CLASE CORRECTA EN ESTE MICROCLUSTER\n",
    "\n",
    "                        short_classes = short_classes.drop(aux_index_sc)\n",
    "                        print(\"Así quedan las clases y sus respectivos clusters.\")\n",
    "                        print(Cj)\n",
    "                        print(num_cluster)\n",
    "                        \n",
    "    an_fin_stm = timer()\n",
    "    an_tot_stm = an_fin_stm - an_ini_stm\n",
    "    \n",
    "    return Cj, short_term_memory, num_cluster, ShortCluster, short_classes,\\\n",
    "    aciertos_stm, index_right_stm, clasif_right_stm, index_wrong_stm, clasif_wrong_stm, \\\n",
    "    an_tot_stm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_t_s(short_term_memory, short_classes, Time_stamps, ventana_de_olvido):\n",
    "    \"\"\" This function updates the short term memory.\n",
    "    INPUT:\n",
    "    - short_memory: Data set for intances didn't recognized\n",
    "    - Time_stamps\n",
    "    - ventana_de_olvido\n",
    "    OUTPUT:\n",
    "    - short_term_memory: is the dataset of the short memory updated\n",
    "    - short_classes: is the dataframe of classes correspondind to the short memory updated.\n",
    "    \"\"\"\n",
    "    # Update time stamp\n",
    "    current_t_s = Time_stamps[-1] #Current time stamp\n",
    "    update_time = current_t_s - ventana_de_olvido # difference_time_stamp es el factor de olvido\n",
    "    short_term_memory = short_term_memory.loc[update_time:, :]\n",
    "    short_term_memory\n",
    "    # Update short_classes \n",
    "    aux_index = short_term_memory.index.tolist()\n",
    "    short_classes = short_classes.loc[aux_index]\n",
    "    \n",
    "    return short_term_memory, short_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get unique values \n",
    "def unique(lista): \n",
    "    valores = []  \n",
    "    # insert the list to the set \n",
    "    list_set = set(lista) \n",
    "    # convert the set to the list \n",
    "    unique_list = (list(list_set)) \n",
    "    for valor in unique_list: \n",
    "        valores.append(valor)\n",
    "        # print(x) \n",
    "    return valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clases_en_ventana(lista_clases):\n",
    "    \"\"\"Esta función regresa un diccionario con la clase y número de instancias que hay.\n",
    "    INPUT:\n",
    "    - clases_totales: es una lista con todas las etiquetas de clases presentadas en la ventana\n",
    "    OUTPUT:\n",
    "    - n_v: el diccionario donde indica clase y número de instancias\n",
    "    \"\"\"\n",
    "    \n",
    "    # Clases e instancias TOTALES por ventana\n",
    "    lista_clases = sorted(lista_clases, reverse=False) # La lista se arregla de mayor a menor.\n",
    "    lista_clases_unique = unique(lista_clases) # Se obtienen los valores únicos (clases)\n",
    "    n_instancias = [len(list(group)) for key, group in groupby(lista_clases)] # Lista con cantidad de\n",
    "    # patrones que hay por clase\n",
    "    C_v_tot = []\n",
    "    for i in lista_clases_unique:\n",
    "        C_v_tot.append(\"clase_\"+str(i))\n",
    "    # using naive method to convert lists to dictionary \n",
    "    diccionario_clases = {} \n",
    "    for key in C_v_tot: \n",
    "        for value in n_instancias: \n",
    "            diccionario_clases[key] = value \n",
    "            n_instancias.remove(value) \n",
    "            break \n",
    "    return diccionario_clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusters_en_ventana(Cj, num_clusters):\n",
    "    \"\"\" Esta función regresa en forma de diccionario las clases detectadas \n",
    "    y sus clusters creados.\n",
    "    INPUT:\n",
    "    - Cj: es una lista que contiene las etiquetas de clases detectadas\n",
    "    -num_clusters: es una lista con el número de clusters por cada clase\n",
    "    OUTPUT:\n",
    "    - diccionario_clusters: es un diccionario que relaciona la clase y el número total de los clusters creados\"\"\"  \n",
    "\n",
    "    Cluster_v = []\n",
    "    for i in Cj:\n",
    "        Cluster_v.append(\"cluster_clase_\"+str(i))\n",
    "    \n",
    "    num_c = num_clusters.copy()\n",
    "    diccionario_clusters = {} \n",
    "    for key in Cluster_v: \n",
    "        for value in num_c: \n",
    "            diccionario_clusters[key] = value \n",
    "            num_c.remove(value) \n",
    "            break\n",
    "    return diccionario_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PREPROCESSING.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>atrib1</th>\n",
       "      <th>atrib2</th>\n",
       "      <th>atrib3</th>\n",
       "      <th>atrib4</th>\n",
       "      <th>atrib5</th>\n",
       "      <th>atrib6</th>\n",
       "      <th>atrib7</th>\n",
       "      <th>atrib8</th>\n",
       "      <th>atrib9</th>\n",
       "      <th>...</th>\n",
       "      <th>atrib33</th>\n",
       "      <th>atrib34</th>\n",
       "      <th>atrib35</th>\n",
       "      <th>atrib36</th>\n",
       "      <th>atrib37</th>\n",
       "      <th>atrib38</th>\n",
       "      <th>atrib39</th>\n",
       "      <th>atrib40</th>\n",
       "      <th>atrib41</th>\n",
       "      <th>clase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>256368</td>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>ecr_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>453300</td>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>domain_u</td>\n",
       "      <td>SF</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256244</td>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>ecr_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>453038</td>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>domain_u</td>\n",
       "      <td>SF</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256453</td>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>ecr_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35995</th>\n",
       "      <td>252105</td>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>ecr_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35996</th>\n",
       "      <td>164573</td>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>ecr_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35997</th>\n",
       "      <td>139950</td>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>ecr_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35998</th>\n",
       "      <td>456598</td>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>326</td>\n",
       "      <td>849</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35999</th>\n",
       "      <td>8782</td>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>ecr_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36000 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  atrib1 atrib2    atrib3 atrib4  atrib5  atrib6  atrib7  \\\n",
       "0          256368       0   icmp     ecr_i     SF    1032       0       0   \n",
       "1          453300       0    udp  domain_u     SF      46      46       0   \n",
       "2          256244       0   icmp     ecr_i     SF    1032       0       0   \n",
       "3          453038       0    udp  domain_u     SF      42      42       0   \n",
       "4          256453       0   icmp     ecr_i     SF    1032       0       0   \n",
       "...           ...     ...    ...       ...    ...     ...     ...     ...   \n",
       "35995      252105       0   icmp     ecr_i     SF    1032       0       0   \n",
       "35996      164573       0   icmp     ecr_i     SF    1032       0       0   \n",
       "35997      139950       0   icmp     ecr_i     SF    1032       0       0   \n",
       "35998      456598       0    tcp      http     SF     326     849       0   \n",
       "35999        8782       0   icmp     ecr_i     SF    1032       0       0   \n",
       "\n",
       "       atrib8  atrib9  ...  atrib33  atrib34  atrib35  atrib36  atrib37  \\\n",
       "0           0       0  ...      255      1.0      0.0     1.00     0.00   \n",
       "1           0       0  ...      255      1.0      0.0     0.01     0.00   \n",
       "2           0       0  ...      255      1.0      0.0     1.00     0.00   \n",
       "3           0       0  ...      255      1.0      0.0     0.01     0.00   \n",
       "4           0       0  ...      255      1.0      0.0     1.00     0.00   \n",
       "...       ...     ...  ...      ...      ...      ...      ...      ...   \n",
       "35995       0       0  ...      255      1.0      0.0     1.00     0.00   \n",
       "35996       0       0  ...      255      1.0      0.0     1.00     0.00   \n",
       "35997       0       0  ...      255      1.0      0.0     1.00     0.00   \n",
       "35998       0       0  ...      255      1.0      0.0     0.01     0.02   \n",
       "35999       0       0  ...      255      1.0      0.0     1.00     0.00   \n",
       "\n",
       "       atrib38  atrib39  atrib40  atrib41    clase  \n",
       "0          0.0      0.0      0.0      0.0   smurf.  \n",
       "1          0.0      0.0      0.0      0.0  normal.  \n",
       "2          0.0      0.0      0.0      0.0   smurf.  \n",
       "3          0.0      0.0      0.0      0.0  normal.  \n",
       "4          0.0      0.0      0.0      0.0   smurf.  \n",
       "...        ...      ...      ...      ...      ...  \n",
       "35995      0.0      0.0      0.0      0.0   smurf.  \n",
       "35996      0.0      0.0      0.0      0.0   smurf.  \n",
       "35997      0.0      0.0      0.0      0.0   smurf.  \n",
       "35998      0.0      0.0      0.0      0.0  normal.  \n",
       "35999      0.0      0.0      0.0      0.0   smurf.  \n",
       "\n",
       "[36000 rows x 43 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your dataset has 36000 instances and 42 attributes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# - - - - - - - - - - - - - - - - STREAM DATA SET - - - - - - - - - - - - - - - - -\n",
    "S\n",
    "# - - - - - - - - - - - - - - - - Delete attrib0 column - - - - - - - - - - - - - - - - - \n",
    "# Here we have a little problem, the first column is unnecessary, \n",
    "# so we must to eliminate but not having a name will not be possible so\n",
    "# we must rename it and after that eliminate.\n",
    "S.rename( columns={'Unnamed: 0':'attrib0'}, inplace=True )\n",
    "del S['attrib0']\n",
    "\n",
    "# - - - - - - - - - - - - - - - - Rearrange our database - - - - - - - - - - - - - - - -\n",
    "# First columns: categorical\n",
    "# After categorical columns: numerical\n",
    "# CLASS column\n",
    "S1, num_col_names, cat_col_names = preprocessing_label_coding(S, class_type)\n",
    "clases_originales = S1['CLASS']\n",
    "\n",
    "rows = S1.shape[0]\n",
    "attributes = S1.shape[1]\n",
    "print(\"Your dataset has \" + str(rows) + \" instances and \" + str(attributes) + \" attributes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clases_originales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "# Naıve Associative Classifier for Online Data (NACOD)\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model train\n",
    "S1, model_train = create_model_train(S1, InitNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(S1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2 = S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1022\n",
       "2     978\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - - - - - - - - - - - - - - - Identify how many classes we have - - - - - - - - - - - - - - - \n",
    "# Classes of my model train\n",
    "Cj = model_train.iloc[:,-1]\n",
    "# Count classes by label\n",
    "Cj = Cj.value_counts(sort=True)\n",
    "Cj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - - - - - - - - - - - - - - - LABEL CLASSES - - - - - - - - - - - - - - -\n",
    "Cj = Cj.keys()\n",
    "Cj = Cj.tolist()\n",
    "#length = len(Cj)\n",
    "Cj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - - - Obtener un D_# por cada clase - SUBSETS OF THE TRAINING DATASET - - - - - - - - - - - - - - -\n",
    "j = 0\n",
    "for i in range(len(Cj)):\n",
    "    globals()['D_'+str(Cj[i])] = model_train[model_train['CLASS']==Cj[i]]\n",
    "    globals()['D_'+str(Cj[i])].pop('CLASS') # Eliminate class\n",
    "    #    model_train[model_train['CLASS'].str.match(Cj[i])] #if the classes were categorical\n",
    "del model_train # Lo borramos\n",
    "# D_1\n",
    "# D_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# CLUSTERING\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# K_means\n",
    "Apply the K means algorithm in each D_x, we will asked how many clusters do we want for each x.\n",
    "\n",
    "Result: \n",
    " * Centroid of each cluster (4) in D_x (8 centroids) \n",
    " * MC_x in wich the CLASS colum will be changed by CLUSTER column based in which instance belongs to what cluster.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Number of clusters for D_3?  5\n",
      "Number of clusters for D_2?  5\n"
     ]
    }
   ],
   "source": [
    "##### - A los sets de cada clase se les añade una columna al final la cual\n",
    "# indica el numero de cluster al que pertenece cada instancia\n",
    "j = 0\n",
    "num_cluster = [] # Empty list for number of clusters\n",
    "for i in range(len(Cj)): # How many Dj\n",
    "    j = i+1\n",
    "    # Se hace el Kmeans con n clústers\n",
    "    num_cluster.append(int(input('Number of clusters for D_'+str(Cj[i])+'? ')))\n",
    "    globals()['kmeansD_'+str(Cj[i])] = KMeans(n_clusters=int(num_cluster[-1]), random_state=0).fit(globals()['D_'+str(Cj[i])])\n",
    "    # Obtener los centroides de cada cluster\n",
    "    globals()['centroidsD_'+str(Cj[i])] = globals()['kmeansD_'+str(Cj[i])].cluster_centers_ \n",
    "    # Column_series es el array de a cuál cluster pertenecen las instancias\n",
    "    column_series = pd.Series(globals()['kmeansD_'+str(Cj[i])].labels_ + 1)\n",
    "    # Ese array lo pasamos a forma de Dataframe\n",
    "    globals()['MC_'+str(Cj[i])] = column_series.to_frame()\n",
    "    # Para poderlo concatenar al model train tenemos que hacer que los índices de las instancias cuadren\n",
    "    globals()['MC_'+str(Cj[i])].index = globals()['D_'+str(Cj[i])].index\n",
    "    # Renombramos a la columna con la palabra CLUSTER\n",
    "    globals()['MC_'+str(Cj[i])].rename( columns={0:'CLUSTER'}, inplace=True )\n",
    "    globals()['MC_'+str(Cj[i])] = pd.concat([globals()['D_'+str(Cj[i])],globals()['MC_'+str(Cj[i])]], axis=1) \n",
    "\n",
    "# del D_1 # Se elimina\n",
    "# del D_3 # Se elimina\n",
    "# MC_1\n",
    "# MC_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crean los micro clusteres - - MC_j_i -  j es la clase - i el cluster - - - - -\n",
    "j = 0\n",
    "n_c = []\n",
    "for j in range(len(Cj)): # Número de clases\n",
    "    for i in range(num_cluster[j]): # Número de clusters \n",
    "        globals()['MC_'+str(Cj[j])+'_'+str(i+1)] = globals()['MC_'+str(Cj[j])][globals()['MC_'+str(Cj[j])]['CLUSTER']==i+1]\n",
    "        n_c.append(len(globals()['MC_'+str(Cj[j])+'_'+str(i+1)]))\n",
    "        # Escribir archivos csv\n",
    "        #globals()['MC_'+str(Cj[j])+'_'+str(i+1)].to_csv('MC_'+str(Cj[j])+'_'+str(i+1)+'.csv')\n",
    "    del globals()['MC_'+str(Cj[j])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[997, 3, 7, 13, 2, 957, 1, 1, 4, 15]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_c # numero de instancias pertenecientes a cada cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Micro clusters información.\n",
    "Se llama a la funcion \"microcluster_information\" para obtener la siguiente información:\n",
    "- Timestamp, Number of instances. Número de instancias, LS Linear sum. Suma lineal\n",
    "- SS Cuadratic sum. Suma cuadrática, Cj label of the class to which they belong. Etiqueta de la clase perteneciente\n",
    "- Centroid. Centroide, Radius. Radio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - - MC_j_i - - - INFORMATION - - - - average vector for numeric attributes\n",
    "# missing to obtain Mode vector for categorical attributes.\n",
    "for j in range(len(Cj)): # Num of classes\n",
    "    for i in range(num_cluster[j]): # Num of clusters\n",
    "        # Time stamp\n",
    "        microcluster_information(j,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Online phase.\n",
    "\n",
    "Classification\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Así comienzan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8aef97fa5a74c60a839cd9abb399036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Longitud de ventana: 2000\n",
      "Patrones en STM: 0\n",
      "clasificados: 2000\n",
      "Tiempo transcurrido: 1.068074995\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "Finalizó la ventana: 1 TimeStamp: 3999 t: 64.0844997[sec] accuracy 100.0\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      " Longitud de ventana: 2000\n",
      "Patrones en STM: 469\n",
      "Analysis\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "clasificados: 3531\n",
      "Tiempo transcurrido: 0.9778924833333335\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "Finalizó la ventana: 2 TimeStamp: 5999 t: 58.67354900000001[sec] accuracy 76.55\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      " Longitud de ventana: 2000\n",
      "Patrones en STM: 454\n",
      "Analysis\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "clasificados: 5092\n",
      "Tiempo transcurrido: 0.9802046916666669\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "Finalizó la ventana: 3 TimeStamp: 7999 t: 58.81228150000001[sec] accuracy 78.05\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      " Longitud de ventana: 2000\n",
      "Patrones en STM: 452\n",
      "Analysis\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "clasificados: 6649\n",
      "Tiempo transcurrido: 1.0226632633333332\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "Finalizó la ventana: 4 TimeStamp: 9999 t: 61.3597958[sec] accuracy 77.85\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      " Longitud de ventana: 2000\n",
      "Patrones en STM: 475\n",
      "Analysis\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "clasificados: 8189\n",
      "Tiempo transcurrido: 1.0391933516666663\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "Finalizó la ventana: 5 TimeStamp: 11999 t: 62.35160109999998[sec] accuracy 77.0\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      " Longitud de ventana: 2000\n",
      "Patrones en STM: 454\n",
      "Analysis\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "clasificados: 9740\n",
      "Tiempo transcurrido: 1.0127211416666664\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "Finalizó la ventana: 6 TimeStamp: 13999 t: 60.76326849999998[sec] accuracy 77.55\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      " Longitud de ventana: 2000\n",
      "Patrones en STM: 464\n",
      "Analysis\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "clasificados: 11289\n",
      "Tiempo transcurrido: 1.005569913333333\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "Finalizó la ventana: 7 TimeStamp: 15999 t: 60.33419479999998[sec] accuracy 77.45\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      " Longitud de ventana: 2000\n",
      "Patrones en STM: 447\n",
      "Analysis\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "clasificados: 12845\n",
      "Tiempo transcurrido: 1.0581332033333335\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "Finalizó la ventana: 8 TimeStamp: 17999 t: 63.48799220000001[sec] accuracy 77.8\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      " Longitud de ventana: 2000\n",
      "Patrones en STM: 458\n",
      "Analysis\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "clasificados: 14403\n",
      "Tiempo transcurrido: 0.9930118700000008\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "Finalizó la ventana: 9 TimeStamp: 19999 t: 59.58071220000005[sec] accuracy 77.9\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      " Longitud de ventana: 2000\n",
      "Patrones en STM: 455\n",
      "Analysis\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "clasificados: 15949\n",
      "Tiempo transcurrido: 1.0534579099999992\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "Finalizó la ventana: 10 TimeStamp: 21999 t: 63.207474599999955[sec] accuracy 77.3\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      " Longitud de ventana: 2000\n",
      "Patrones en STM: 480\n",
      "Analysis\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "clasificados: 17484\n",
      "Tiempo transcurrido: 0.9661028733333334\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "Finalizó la ventana: 11 TimeStamp: 23999 t: 57.966172400000005[sec] accuracy 76.75\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      " Longitud de ventana: 2000\n",
      "Patrones en STM: 454\n",
      "Analysis\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "\n",
      "  EXTENSIÓN de clase\n",
      "La clase cercana es : 2, pero la clase con mayor repetición es: 1\n",
      "Se descarta esta extensión\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2]\n",
      "[5, 5]\n",
      "NUEVA CLASE\n",
      "La nueva clase es: 1\n",
      "NUEVA CLASE\n",
      "La clase 1 ya existía.\n",
      "NUEVA CLASE\n",
      "La clase 1 ya existía.\n",
      "NUEVA CLASE\n",
      "La clase 1 ya existía.\n",
      "NUEVA CLASE\n",
      "La clase 1 ya existía.\n",
      "NUEVA CLASE\n",
      "La clase 1 ya existía.\n",
      "clasificados: 19050\n",
      "Tiempo transcurrido: 1.0500658799999996\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2, 1]\n",
      "[5, 5, 1]\n",
      "Finalizó la ventana: 12 TimeStamp: 25999 t: 63.00395279999998[sec] accuracy 78.3\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      " Longitud de ventana: 2000\n",
      "Patrones en STM: 52\n",
      "clasificados: 21002\n",
      "Tiempo transcurrido: 1.1348283916666673\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2, 1]\n",
      "[5, 5, 1]\n",
      "Finalizó la ventana: 13 TimeStamp: 27999 t: 68.08970350000004[sec] accuracy 97.6\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      " Longitud de ventana: 2000\n",
      "Patrones en STM: 94\n",
      "clasificados: 22960\n",
      "Tiempo transcurrido: 1.0586171699999984\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2, 1]\n",
      "[5, 5, 1]\n",
      "Finalizó la ventana: 14 TimeStamp: 29999 t: 63.51703019999991[sec] accuracy 97.89999999999999\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      " Longitud de ventana: 2000\n",
      "Patrones en STM: 138\n",
      "Analysis\n",
      "NUEVA CLASE\n",
      "La clase 1 ya existía.\n",
      "NUEVA CLASE\n",
      "La clase 1 ya existía.\n",
      "NUEVA CLASE\n",
      "La clase 1 ya existía.\n",
      "clasificados: 24916\n",
      "Tiempo transcurrido: 1.0522842483333326\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2, 1]\n",
      "[5, 5, 1]\n",
      "Finalizó la ventana: 15 TimeStamp: 31999 t: 63.13705489999995[sec] accuracy 97.8\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      " Longitud de ventana: 2000\n",
      "Patrones en STM: 68\n",
      "clasificados: 26869\n",
      "Tiempo transcurrido: 1.0641343466666664\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2, 1]\n",
      "[5, 5, 1]\n",
      "Finalizó la ventana: 16 TimeStamp: 33999 t: 63.848060799999985[sec] accuracy 97.65\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      " Longitud de ventana: 2000\n",
      "Patrones en STM: 106\n",
      "Analysis\n",
      "NUEVA CLASE\n",
      "La clase 1 ya existía.\n",
      "clasificados: 28831\n",
      "Tiempo transcurrido: 1.1514980200000007\n",
      "Así quedan las clases y sus respectivos clusters.\n",
      "[3, 2, 1]\n",
      "[5, 5, 1]\n",
      "Finalizó la ventana: 17 TimeStamp: 35999 t: 69.08988120000004[sec] accuracy 98.1\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    }
   ],
   "source": [
    "total = len(S1)\n",
    "#ventana = 0\n",
    "n_ventana = 0\n",
    "Time_stamps = [ ]\n",
    "contador = 0\n",
    "columns = ['Clase correcta', 'Clasificado en', \"Ventana\", \"GHOS\", \"STM\", 'Acierto']\n",
    "columns_stm = ['Clase correcta', 'Clasificado en', 'Ventana', \"GHOS\"]\n",
    "col_clasif_stm = ['Clase_correcta', 'Clasificado en', 'GHOS', 'Acierto', 'Ventana']\n",
    "columns_time = ['Ventana', 'TS', 'Accuracy', 'Tiempo transcurrido [sec]', \"Instancias clase_1\",\n",
    "                \"Instancias clase_2\", \"Instancias clase_3\", \"Instancias clase_4\", \"Instancias clase_5\", \"Instancias clase_6\", \n",
    "                \"Clasificadas clase_1\", \"Clasificadas clase_2\", \"Clasificadas clase_3\", \"Clasificadas clase_4\", \n",
    "                \"Clasificadas clase_5\", \"Clasificadas clase_6\", \"Cluster clase_1\", \"Cluster clase_2\", \"Cluster clase_3\",\n",
    "                \"Cluster clase_4\", \"Cluster clase_5\", \"Cluster clase_6\"]\n",
    "index_no_emerging = []\n",
    "col_no_emerging = [\"Ventana\", \"Cluster STM\", 'clase original', 'clase propuesta', 'error', 'instancias', 'T']\n",
    "no_emerging = [] \n",
    "clases = []\n",
    "clases_stm = []\n",
    "clasif_right_stm = []\n",
    "clasif_wrong_stm = []\n",
    "index = []\n",
    "index_stm= []\n",
    "index_right_stm = []\n",
    "index_wrong_stm = []\n",
    "index_time = [] # Para dataframe de tiempo\n",
    "times = []\n",
    "ghos_stm = []\n",
    "accuracy_ventana = []\n",
    "aciertos_clases =[]\n",
    "aciertos_stm = 0\n",
    "short_term_memory = pd.DataFrame()\n",
    "short_classes = pd.DataFrame()\n",
    "####### - - - - - - - - - - - \n",
    "# para medir el tiempo de STM (S) y de clasificación (C)\n",
    "tiempos_c_s = []\n",
    "col_time = [\"Ventana\", \"tiempo tot [sec]\", \"t clasificacion\",\n",
    "\"g_h_o_s\", \"Correct clas\", \"Incorrect class\", \"t mandar a stm\", \"time todo stm\", \"Frame stm\",\n",
    "\"Clusters stm\", \"analysis stm\", \"update stm\", \"Analysis\", 'STM', 'A0', 'A1', 'A2', 'A3', \n",
    "'A4', 'Calculo_Umbral', 'A6', 'A7', \"Extension\", \"E0\", \"E1\", \"E2\", \"E3\", \"Umbral\", \"U0\",\n",
    "\"U1\", \"U2\", \"U3\", \"U4\"]\n",
    "\n",
    "\n",
    "#While para recorrer todo el dataset\n",
    "print(\"Así comienzan las clases y sus respectivos clusters.\")\n",
    "print(Cj)\n",
    "print(num_cluster)\n",
    "while S1.size != 0:\n",
    "    clasificados = 0\n",
    "    for i in tqdm_notebook(range(0, math.ceil(total/paso))):\n",
    "        \n",
    "        aciertos = 0\n",
    "        # Número de patrones que no se mandan a la STM\n",
    "        #clasificados = 0\n",
    "        window = S1[:paso] #window contiene las instancias de la ventana\n",
    "        Time_stamps.append(window.index[-1])\n",
    "        # Aquí las instancias se borran del dataset y se pasan a la ventana\n",
    "        aux_index = window.index.tolist()\n",
    "        S1 = S1.drop(aux_index)\n",
    "        n_ventana = n_ventana + 1\n",
    "        c_v_tot = [] # Es una lista vacía para almacenar cuantos patrones\n",
    "        # y a qué clase pertenecen por ventana.  \n",
    "        c_v_det = [] # Es una lista vacía que almacena los patrones y sus clases\n",
    "        # que fueron clasificadas correctamente en la ventana.\n",
    "\n",
    "        print(\"\\n Longitud de ventana: \" + str(len(window)))\n",
    "        ventana_size = len(window)\n",
    "        TimeInit = timer()\n",
    "    # - - - - - ¿Cuánto se tarda en saber si lo clasifica o se va a la STM?\n",
    "        t_clasif = 0.0 #Variable de tipo float para ir almacenando el tiempo en cada ventana.\n",
    "        #################\n",
    "        ################\n",
    "        t_ghos = 0.0\n",
    "\n",
    "        t_correct_class = 0.0\n",
    "        t_c_incorrect = 0.0\n",
    "        t_sent_stm = 0.0 \n",
    "\n",
    "        ti_stm1 = tf_stm1 = ti_stm2 = tf_stm2 = ti_stm3 = tf_stm3 = ti_stm4 = tf_stm4 = 0.0    \n",
    "        t_stm = t_stm1 = 0.0\n",
    "        an_tot_stm = 0.0\n",
    "    ## Inicializar variables para calcular el tiempo de ejecución de la función Analysis\n",
    "        A0 = A1 = A2 = A3 = A4 = A5 = A6 = A7 = 0.0\n",
    "        E0 = E1 = E2 = E3 = 0.0\n",
    "        U0 = U1 = U2 = U3 = U4 = U4_0 = U4_1 = 0.0\n",
    "        # While para recorrer las instancias que hay en la ventana\n",
    "        while window.size != 0:\n",
    "\n",
    "            # Start nos ayuda a medir el tiempo de inicio de la ventana\n",
    "            start = timer()\n",
    "\n",
    "            X_test = window.iloc[[0]].drop(['CLASS'], axis=1)\n",
    "            y_test = window.iloc[[0]]['CLASS']\n",
    "            c_v_tot.append(int(y_test)) # Aquí se van almacenando las clases que se presentan en la ventana\n",
    "           # print(c_v_tot[-1])\n",
    "            indice = X_test.index.tolist()[0]\n",
    "            # print(\"indice\" + str(indice))\n",
    "            # Aquí la instancia a analizar se borra de la ventana\n",
    "            aux_index = X_test.index.tolist()\n",
    "            window = window.drop(aux_index)\n",
    "\n",
    "            ###TIEMPO\n",
    "            ################### FUNCION GHOS #########################################\n",
    "            start_ghos = timer()\n",
    "            winning_class, winning_cluster, ghos = g_h_o_s(num_cluster, Cj, X_test, 'classification')\n",
    "            end_ghos = timer()\n",
    "            t_ghos = t_ghos + (end_ghos - start_ghos) # El tiempo es acumulativo\n",
    "            ##########################################################################\n",
    "            \n",
    "            \n",
    "            start_clasif = timer()\n",
    "            \n",
    "            if opc_clasif == 1:            \n",
    "                aciertos_clases, index, clases, aciertos, c_v_det, short_classes, \\\n",
    "                short_term_memory, index_stm, clases_stm, ghos_stm, clasificados = clasification_original(winning_class, \\\n",
    "                aciertos_clases, winning_cluster, y_test, X_test, index, indice,n_ventana, ghos, clases, \\\n",
    "                aciertos, c_v_det, short_classes, short_term_memory, index_stm, clases_stm, ghos_stm, clasificados)\n",
    "        \n",
    "                \n",
    "            else: # Aqui la clasificación debe ser con un umbral de similitud (si se elige el número 2)\n",
    "                print(\"NADA\")\n",
    "\n",
    "        # - - - - - \n",
    "        ti_stm = timer() # Tiempo inicial del análisis de la stm\n",
    "\n",
    "\n",
    "        print(\"Patrones en STM: \" + str(len(short_term_memory)))\n",
    "        # Si cumple la condición, se analiza la STM\n",
    "        if len(short_term_memory)>= n_elements_stm:\n",
    "\n",
    "            ti_stm1 = timer()\n",
    "            # Me da las instancias mandadas al short term memory\n",
    "            instancias_stm = pd.DataFrame(clases_stm, index_stm, columns_stm)\n",
    "            tf_stm1 = timer()\n",
    "\n",
    "\n",
    "            ti_stm2 = timer()\n",
    "            # Creación de los clusters en el stm\n",
    "            Clusters, n_clusters_stm = clusters_stm(short_term_memory, mc_stm)\n",
    "            tf_stm2 = timer()\n",
    "\n",
    "\n",
    "            ti_stm3 = timer()\n",
    "            # Las siguientes 5 líneas hacen referencia a la función que checa si el cluster\n",
    "            # es o no válido. Si es válido, hace la asignación como extensión de la clase\n",
    "            # o clase emergente.\n",
    "            # - - - REVISAR LOS TIEMPOS DE ESTA FUNCIÓN- - - - - \n",
    "            ##Cj, short_term_memory, num_cluster, ShortCluster,short_classes,\\\n",
    "            ##aciertos_stm,index_right_stm, clasif_right_stm,index_wrong_stm, \\\n",
    "            ##clasif_wrong_stm, an_tot_stm = analysis_stm(short_term_memory, short_classes, Clusters,\\\n",
    "            ##n_clusters_stm,Cj, clases_originales, num_cluster, aciertos_stm,index_right_stm, clasif_right_stm,\\\n",
    "            ##index_wrong_stm,clasif_wrong_stm, instancias_stm, n_ventana)\n",
    "\n",
    "            #- - - - REVISAR LOS TIEMPOS DE ESTA FUNCIÓN- - - - - \n",
    "            print(\"Analysis\")\n",
    "            ## Tiempo de ejecución\n",
    "\n",
    "            an_tot_stm = 0.0\n",
    "            an1_stm = 0.0\n",
    "            an_ini_stm = timer()\n",
    "\n",
    "            for i in range(n_clusters_stm[-1]):\n",
    "                ##\n",
    "                A0i = timer()\n",
    "                n_cluster_stm = i + 1\n",
    "                #Este es el cluster del short term memory a analizar\n",
    "                ShortCluster = Clusters[Clusters['CLUSTER']==i+1]\n",
    "                # Es cohesivo?\n",
    "                # Calcular Silhouette. Para ello debemos de tener el centroide del microcluster.\n",
    "                # Centroid LS/N\n",
    "                N = len(ShortCluster.index)\n",
    "                # print(\"\\n El cluster \" + str(i+1) + \" tiene: \" + str(N) + \" instancias.\")\n",
    "                LS = (ShortCluster.sum(axis=0)).drop(labels=['CLUSTER'])\n",
    "                Centroid = LS / N\n",
    "                Silhouette = 0 \n",
    "                A0f = timer()\n",
    "                A0 = A0 +(A0f -A0i)\n",
    "                ##\n",
    "\n",
    "                # - - - - - VALIDACION DEL CLUSTER - - - - - - - -     \n",
    "                # Se verifica si es representativo, si lo es, se verifica si es cohesivo (Silhouette)\n",
    "                # ...To identify if a cluster is cohesive, a modified silhouette coefficient will be used...\n",
    "\n",
    "                # - - - - - - REPRESENTATIVO - - - - - - - - \n",
    "                if N >= n_representative: #Si es representativo entra a este for\n",
    "                    # print(\"Si es representativo\")\n",
    "                # Silhouette = b-a / max(a,b)\n",
    "\n",
    "                ##\n",
    "                    A1i = timer()\n",
    "                    clase_cercana, cluster_cercano, b = g_h_o_s(num_cluster, Cj, Centroid, 'novel_detection')\n",
    "                    \n",
    "                    A1f = timer()\n",
    "                    A1 = A1 + (A1f - A1i)\n",
    "                ##\n",
    "                ##\n",
    "                    A2i = timer() \n",
    "                    \n",
    "\n",
    "                # a standar deviation of the distance between each instance of the new microcluster\n",
    "                # and the new microcluster centroid\n",
    "                    a = []\n",
    "                    for i in range(len(ShortCluster)):\n",
    "                    # a es una lista que almacena las distancias euclideanas entre cada instancia de ese\n",
    "                    # microcluster y el centroide.\n",
    "                        a.append(np.linalg.norm(ShortCluster.iloc[[i]].drop(['CLUSTER'], axis=1) - Centroid))\n",
    "                    # Ya obtenidas las distancias euclideanas calculamos la desviación estándar\n",
    "                    # sqrt (((x_prom - x)**2 suma) / N )\n",
    "                    a = math.sqrt(((mean(a) - a)**2).sum() / len(a))\n",
    "                    # print(\"a: \" + str(a))\n",
    "\n",
    "                    A2f = timer()\n",
    "                    A2 = A2 + (A2f -A2i)\n",
    "                ##\n",
    "\n",
    "                ##                \n",
    "                    if max(b,a) != 0:\n",
    "\n",
    "                        A3i = timer()\n",
    "\n",
    "                        Silhouette = (b - a) / max(b, a)\n",
    "                    # Verificar si el cluster es válido, significa que Silhouette > 0,\n",
    "                    # si es representativo y válido: instancias se eliminan del short term memory\n",
    "                        #print(\"Silhouette: \" + str(Silhouette))\n",
    "                        # print(\"b = \" + str(b) + \". a = \" + str(a))\n",
    "\n",
    "                        A3f = timer()\n",
    "                        A3 = A3 + (A3f - A3i)\n",
    "                 ##   \n",
    "                    # - - - - - - - - - - - COHESIVO - - - - - -\n",
    "                        if Silhouette > 0: # El cluster es válido\n",
    "\n",
    "                        ## A4 es para eliminar las instancias del STM\n",
    "                            A4i = timer()\n",
    "\n",
    "                            aux_index_sc = ShortCluster.index.tolist()\n",
    "                        # Borrar estas instancias del short term memory y también sus clases\n",
    "                            short_term_memory = short_term_memory.drop(aux_index_sc)\n",
    "\n",
    "                            A4f = timer()\n",
    "                            A4 = A4 + (A4f - A4i)\n",
    "                        ##\n",
    "\n",
    "                        # - - - - NOVELTY PROCESS - - - - \n",
    "                        # - - - - - - Threshold - - - - - -\n",
    "                        # T = la media de las distancias del centroide del microcluster de la clase \n",
    "                        # más cercana con respecto a los demás microclusters de esa clase\n",
    "\n",
    "                        ## A5 es el cálculo del umbral\n",
    "                            A5i = timer()\n",
    "\n",
    "                            ##print(\"\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "                            #print(\"- - - - - - - - - UMBRAL - - - - - - - - - - - - - - - \\n\")\n",
    "\n",
    "\n",
    "                            ##print(\"Cálculo de T\")\n",
    "                            ## T0 nos da la distancia entre el centroide de ese nuevo MC con respecto al centroide de la clase más cercana\n",
    "                            U0i = timer()\n",
    "\n",
    "                            Centroide_cercano = globals()['Centroid_MC_'+str(clase_cercana)+'_'+str(cluster_cercano)]\n",
    "                            # print(\"Distancia entre el Centroide_\"+ str(clase_cercana)+\"_\"+str(cluster_cercano) + \" con respecto a:\")\n",
    "\n",
    "                            U0f = timer()\n",
    "                            U0 = U0 + (U0f - U0i) \n",
    "                            ##\n",
    "\n",
    "                            ## T1 tiempo que se tarda en saber cuantos clusters hay en la clase más cercana\n",
    "                            U1i = timer()\n",
    "\n",
    "                            T = []\n",
    "                            ##print(\"La clase cercana es: \" + str(clase_cercana) + \" y el cluster cercano es: \" + str(cluster_cercano))\n",
    "                            class_index = Cj.index(clase_cercana) # class index guarda la posición de Cj donde está la clase más cercana\n",
    "                            # esta posición la busco en num_cluster para saber cuantos clusters hay en la clase más cercana \n",
    "\n",
    "                            U1f = timer()\n",
    "                            U1 = U1 + (U1f - U1i)\n",
    "                            ##\n",
    "\n",
    "                            ##\n",
    "                            U2i = timer()\n",
    "\n",
    "                            for j in range(0, num_cluster[class_index]): # Modifiqué porque estaba malrange(0, cluster_cercano)\n",
    "                                i = j + 1\n",
    "                                if i != cluster_cercano: # Si el índice i coincide con cluster cercano no entra en esta sentencia porque\n",
    "                                    # no debe calcular la distancia con respecto a él mismo\n",
    "                                    # print(\"Se compara con clase: \"  + str(clase_cercana) + \", cluster: \"+ str(i))\n",
    "                                    # la distancia se estaría compárando con respecto al mismo centroide \n",
    "                                    T.append(np.linalg.norm(globals()['Centroid_MC_'+str(clase_cercana)+'_'+str(i)] - Centroide_cercano))\n",
    "                                    # print(\"Centroide más cercano vs Centroide_\" + str(clase_cercana) + \"_\"+str(i+1))\n",
    "                            ##print(\"T antes del promedio: \" + str(T))\n",
    "\n",
    "                            U2f = timer()\n",
    "                            U2 = U2 + (U2f - U2i)\n",
    "                            ##\n",
    "                            ##print(\"len(T)\" + str(len(T)))\n",
    "\n",
    "                            if len(T) >= 1: #Significa que hay al menos 2 clusteres de esa clase\n",
    "                            ##\n",
    "                                U3i = timer()\n",
    "\n",
    "                                ##print(\"T tiene más de un micro cluster en esa clase.\")\n",
    "                                T = sum(T)/len(T)\n",
    "                                ##print(\"T = \" + str(T))\n",
    "\n",
    "                                U3f = timer()\n",
    "                                U3 = U3 + (U3f - U3i)\n",
    "                                ##\n",
    "\n",
    "                            else: #Significa que solo hay un cluster de esa clase\n",
    "                                ##\n",
    "                                U4i = timer()\n",
    "\n",
    "                            # Si solo hay un microcluster de esa clase, T es calculado como:\n",
    "                            # la desviaciÓn estÁndar de la distancia euclideana entre el centroide del microcluster mÁs cercano y sus instancias.\n",
    "\n",
    "\n",
    "                                ##print(\"El MC mÁs cercano es MC_\" +str(clase_cercana)+'_'+str(cluster_cercano))\n",
    "\n",
    "                                ##print(\"T solo tiene 1 microcluster en esa clase, hay que recalcular\")\n",
    "                                # Se inicializa T = [] para hacer el promedio entre el \n",
    "                                # Centroide y sus instancias\n",
    "                                T = [] \n",
    "                                ##print(str(len(globals()['MC_'+str(clase_cercana)+'_'+str(cluster_cercano)])))\n",
    "                                # for que recorre instancia por instancia del microcluster más cercano (mp).\n",
    "\n",
    "\n",
    "                                # DISTANCIA EUCLIDEANA\n",
    "                                # Se restan las distancias\n",
    "                                d_euc = globals()['MC_'+str(clase_cercana)+'_'+str(cluster_cercano)].drop(['CLUSTER'], axis=1) - globals()['Centroid_MC_'+str(clase_cercana)+'_'+str(cluster_cercano)]\n",
    "                                # Se elevan al cuadrado\n",
    "                                d_euc = d_euc * d_euc\n",
    "                                # Se hace la sumatoria \n",
    "                                d_euc = np.sum(d_euc, axis=1)\n",
    "                                # Se obtiene la raÍz cuadrada\n",
    "                                d_euc = d_euc **(1/2)\n",
    "                                # CÁlculo de desviaciÓn estÁndar\n",
    "                                T = math.sqrt(((mean(d_euc) - d_euc)**2).sum() / len(d_euc))\n",
    "                                ##print(\"T: \" + str(T))\n",
    "                            # ¿Existente o nueva clase?                                               \n",
    "\n",
    "                                U4f = timer()\n",
    "                                U4 = U4 + (U4f - U4i)\n",
    "\n",
    "\n",
    "                            A5f = timer()\n",
    "                            A5 = A5 + (A5f - A5i)\n",
    "\n",
    "\n",
    "                            # - - - - - - - EXTENSIÓN DE CLASE - - - - - - \n",
    "                            if b < T:  #El nuevo microcluster se considera una extensión de la clase\n",
    "                            #print(\"B: \" + str(b) + \", T: \" + str(T))\n",
    "                            #print(\"Clust cerc: \" +str(cluster_cercano) + \"clase cercana: \" + str(clase_cercana))\n",
    "\n",
    "                                ## A6 es la extensión de clase\n",
    "                                A6i = timer()\n",
    "\n",
    "                                print(\"\\n  EXTENSIÓN de clase\")\n",
    "\n",
    "                                Cj, num_cluster, aciertos_stm, index_right_stm, clasif_right_stm,\\\n",
    "                                index_wrong_stm, clasif_wrong_stm, short_classes = class_extension(Cj,\\\n",
    "                                clase_cercana, num_cluster, ShortCluster, aux_index_sc, short_classes,\\\n",
    "                                aciertos_stm, index_right_stm, clasif_right_stm, index_wrong_stm,\\\n",
    "                                clasif_wrong_stm, cluster_cercano, instancias_stm, n_ventana, n_cluster_stm,\\\n",
    "                                N, T)\n",
    "                                print(\"Así quedan las clases y sus respectivos clusters.\")\n",
    "                                print(Cj)\n",
    "                                print(num_cluster)\n",
    "\n",
    "                            # - - - - - - - NUEVA CLASE - - - - - - - - \n",
    "                            else: #El microcluster se considera una clase emergente\n",
    "\n",
    "                                ## A7 es para la clase emergente\n",
    "                                A7i = timer() \n",
    "\n",
    "                                print(\"NUEVA CLASE\")\n",
    "                                Cj, num_cluster, aciertos_stm, index_right_stm, clasif_right_stm,\\\n",
    "                                index_wrong_stm,clasif_wrong_stm, short_classes = emerging_class(Cj,\\\n",
    "                                clases_originales, num_cluster, ShortCluster,aux_index_sc, short_classes,\\\n",
    "                                aciertos_stm, index_right_stm, clasif_right_stm,index_wrong_stm,clasif_wrong_stm,\\\n",
    "                                instancias_stm, n_ventana, n_cluster_stm, N, T)\n",
    "                                \n",
    "                                A7f = timer()\n",
    "                                A7 = A7 + (A7f - A7i)\n",
    "                                ##\n",
    "\n",
    "        \n",
    "            an_fin_stm = timer()\n",
    "            an_tot_stm = an_fin_stm - an_ini_stm                    \n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "        \n",
    "            tf_stm3 = timer() \n",
    "\n",
    "\n",
    "            ti_stm4 = timer()\n",
    "            # Actualización de la Short Term Memory\n",
    "            short_term_memory, short_classes = update_t_s(short_term_memory, short_classes,\\\n",
    "            Time_stamps, ventana_de_olvido)\n",
    "            del Clusters\n",
    "            tf_stm4 = timer()\n",
    "\n",
    "        tf_stm = timer() #Tiempo final del análisis de la stm\n",
    "        \n",
    "        print(\"clasificados: \" + str(clasificados))\n",
    "        # Accuracy por ventana\n",
    "        #accuracy_ventana.append([(aciertos/clasificados)*100])\n",
    "        accuracy_ventana.append([(aciertos/ventana_size)*100])\n",
    "\n",
    "        # --- CALCULOS DE TIEMPO ----\n",
    "        TimeFin = timer()\n",
    "        ElapseTime = TimeFin - TimeInit #Tiempo \n",
    "        print(\"Tiempo transcurrido: \" + str(ElapseTime/60))\n",
    "        t_stm = tf_stm -ti_stm # t_stm = tf_stm - ti_stm\n",
    "        t_stm1 = tf_stm1 - ti_stm1\n",
    "        t_stm2 = tf_stm2 - ti_stm2\n",
    "        t_stm3 = tf_stm3 - ti_stm3\n",
    "        t_stm4 = tf_stm4 - ti_stm4\n",
    "\n",
    "        # - - - - - - - - \n",
    "        # tiempos de clasificación y de ventana STM\n",
    "\n",
    "        tiempo_c_s = {\"Ventana\": n_ventana, \"tiempo tot [sec]\": ElapseTime, \"t clasificacion\": t_clasif, \n",
    "        \"g_h_o_s\": t_ghos, \"Correct clas\": t_correct_class, \"Incorrect class\": t_c_incorrect, \n",
    "        \"t mandar a stm\": t_sent_stm, \"time todo stm\": t_stm, \"Frame stm\": t_stm1, \"Clusters stm\": t_stm2,\n",
    "        \"analysis stm\": t_stm3, \"update stm\": t_stm4, \"Analysis\": an_tot_stm, 'STM':0, 'A0': A0, 'A1': A1,\n",
    "        'A2': A2, 'A3': A3, 'A4': A4, 'Calculo_Umbral': A5, 'A6': A6, 'A7': A7, \"Extension\": 0, \"E0\": E0, \"E1\": E1,\n",
    "        \"E2\":E2, \"E3\": E3, \"Umbral\": 0, \"U0\": U0, \"U1\": U1, \"U2\": U2, \"U3\": U3, \"U4\": U4}\n",
    "        ## t_stm, t_stm3, an_tot_stm \n",
    "\n",
    "        tiempos_c_s.append(tiempo_c_s)\n",
    "\n",
    "\n",
    "        # Clases e instancias TOTALES por ventana\n",
    "        c_v_tot = clases_en_ventana(c_v_tot)\n",
    "        c_v_det = clases_en_ventana(c_v_det)\n",
    "        # Clusteres de cada clase por ventana\n",
    "        cluster_ventana = clusters_en_ventana(Cj, num_cluster)\n",
    "\n",
    "        # Las siguientes 3 líneas son para crear un datarfame donde se almacenen los tiempos por ventana\n",
    "        new_time = {\"Ventana\": n_ventana, 'TS': Time_stamps[-1], \"Accuracy\": accuracy_ventana[-1][0],\\\n",
    "        \"Tiempo transcurrido [sec]\": ElapseTime,\\\n",
    "        \"Instancias clase_1\": c_v_tot['clase_1'] if c_v_tot.get('clase_1') else 'False',     # Esta condicion nos da el número de patrones por clase pero si no hay nos manda un False\n",
    "        \"Instancias clase_2\": c_v_tot['clase_2'] if c_v_tot.get('clase_2') else 'False',\n",
    "        \"Instancias clase_3\": c_v_tot['clase_3'] if c_v_tot.get('clase_3') else 'False',\n",
    "        \"Instancias clase_4\": c_v_tot['clase_4'] if c_v_tot.get('clase_4') else 'False',\n",
    "        \"Instancias clase_5\": c_v_tot['clase_5'] if c_v_tot.get('clase_5') else 'False',\n",
    "        \"Instancias clase_6\": c_v_tot['clase_6'] if c_v_tot.get('clase_6') else 'False',                \n",
    "        \"Clasificadas clase_1\": c_v_det['clase_1'] if c_v_det.get('clase_1') else 'False',\n",
    "        \"Clasificadas clase_2\": c_v_det['clase_2'] if c_v_det.get('clase_2') else 'False',\n",
    "        \"Clasificadas clase_3\": c_v_det['clase_3'] if c_v_det.get('clase_3') else 'False',\n",
    "        \"Clasificadas clase_4\": c_v_det['clase_4'] if c_v_det.get('clase_4') else 'False',\n",
    "        \"Clasificadas clase_5\": c_v_det['clase_5'] if c_v_det.get('clase_5') else 'False',\n",
    "        \"Clasificadas clase_6\": c_v_det['clase_6'] if c_v_det.get('clase_6') else 'False',\n",
    "        \"Cluster clase_1\":cluster_ventana['cluster_clase_1'] if cluster_ventana.get('cluster_clase_1') else 'False',\n",
    "        \"Cluster clase_2\":cluster_ventana['cluster_clase_2'] if cluster_ventana.get('cluster_clase_2') else 'False',\n",
    "        \"Cluster clase_3\":cluster_ventana['cluster_clase_3'] if cluster_ventana.get('cluster_clase_3') else 'False',\n",
    "        \"Cluster clase_4\":cluster_ventana['cluster_clase_4'] if cluster_ventana.get('cluster_clase_4') else 'False',\n",
    "        \"Cluster clase_5\":cluster_ventana['cluster_clase_5'] if cluster_ventana.get('cluster_clase_5') else 'False',\n",
    "        \"Cluster clase_6\":cluster_ventana['cluster_clase_6'] if cluster_ventana.get('cluster_clase_6') else 'False'}\n",
    "\n",
    "        index_time.append(n_ventana) #\n",
    "        times.append(new_time)\n",
    "        \n",
    "        print(\"Así quedan las clases y sus respectivos clusters.\")\n",
    "        print(Cj)\n",
    "        print(num_cluster)\n",
    "        # print(aciertos_ventana)    \n",
    "        print(\"Finalizó la ventana: \" + str(n_ventana) + \" TimeStamp: \" +  str(Time_stamps[-1]) + \" t: \" + str(ElapseTime) + \"[sec]\" + ' accuracy ' + str(accuracy_ventana[-1][0]))\n",
    "        print(\" - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \")\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28831"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1962"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aciertos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "-----\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[100.0],\n",
       " [76.55],\n",
       " [78.05],\n",
       " [77.85],\n",
       " [77.0],\n",
       " [77.55],\n",
       " [77.45],\n",
       " [77.8],\n",
       " [77.9],\n",
       " [77.3],\n",
       " [76.75],\n",
       " [78.3],\n",
       " [97.6],\n",
       " [97.89999999999999],\n",
       " [97.8],\n",
       " [97.65],\n",
       " [98.1]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_ventana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la clase cercana es 2 y el microcluster cercano es 1\n",
    "num_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Guardar y graficar información\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar el accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing library \n",
    "import csv\n",
    "# opening the csv file in 'w+' mode \n",
    "file = open('accuracy_' + str(cadena) +'.csv', 'w+', newline ='')# writing the data into the file \n",
    "with file:     \n",
    "    write = csv.writer(file) \n",
    "    write.writerows(accuracy_ventana) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## accuracy_ventana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar tiempos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe de tiempo\n",
    "Tiempos = pd.DataFrame(times, index_time, columns_time)\n",
    "Tiempos.to_csv('Tiempos_' + str(cadena) +'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tiempos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desglose de tiempos por sección del programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Dataframe de tiempo por sección\n",
    "T_desglose = pd.DataFrame(tiempos_c_s, index_time, col_time)\n",
    "T_desglose.to_csv('T_desglose' + str(cadena) +'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_desglose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Graficas\n",
    "---\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataChunk = list(range(1, n_ventana + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(DataChunk, accuracy_ventana, label = \"STM =\" +str(n_clusters_stm[-1])+ \", MC = \" +str(num_cluster))\n",
    "plt.xlabel('Data Chunk')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title(\"Accuracy del banco:\")\n",
    "plt.legend()\n",
    "plt.savefig('Accuracy.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiempos = Tiempos['Tiempo transcurrido [sec]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiempos = tiempos/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(DataChunk, tiempos, label = \"STM =\" +str(n_clusters_stm[-1])+ \", MC = \" +str(num_cluster))\n",
    "plt.xlabel('Data Chunk')\n",
    "plt.ylabel('Tiempo [min])')\n",
    "locs, labels = plt.xticks()  # Get the current locations and labels.\n",
    "#plt.xticks(np.arange(0, 250, step=20))  # Set label locations.\n",
    "plt.grid(True)\n",
    "plt.title(\"Tiempos\")\n",
    "plt.legend()\n",
    "plt.savefig('Tiempo_x_ventana.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar microclusteres creados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se guardan los micro clusteres creados- - MC_j_i -  j es la clase - i el cluster - - - - -\n",
    "j = 0\n",
    "n_c = []\n",
    "for j in range(len(Cj)): # Número de clases\n",
    "    for i in range(num_cluster[j]): # Número de clusters \n",
    "        # Escribir archivos csv\n",
    "        globals()['MC_'+str(Cj[j])+'_'+str(i+1)].to_csv('MC_'+str(Cj[j])+'_'+str(i+1)+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar los patrones clasificados por el NACOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe de las instancias clasificadas correctamente\n",
    "patrones_clasificaciones_NACOD = pd.DataFrame(clases, index, columns)\n",
    "patrones_clasificaciones_NACOD.to_csv('patrones_clasificaciones_NACOD.csv')\n",
    "patrones_clasificaciones_NACOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar los patrones mandados a STM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Son todas las instancias que NACOD no pudo clasificar y se fueron a la memoria corta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe del histórico de la información de las instancias que llegaron al\n",
    "# short term memory durante la ejecución del programa.\n",
    "patrones_mandados_a_STM = pd.DataFrame(clases_stm, index_stm, columns_stm)\n",
    "patrones_mandados_a_STM.to_csv('patrones_mandados_a_STM.csv')\n",
    "patrones_mandados_a_STM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patrones que se detectaron en extensión o en nueva clase pero que son erroneos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_no_emerging = list(range(1,len(no_emerging)+1))\n",
    "Clases_no_emerging = pd.DataFrame(no_emerging, index_no_emerging, col_no_emerging)\n",
    "Clases_no_emerging.to_csv('Clusters_desechados.csv')\n",
    "Clases_no_emerging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como queda STM al final del análisis\n",
    "short_term_memory # STM Actualizado\n",
    "short_term_memory.to_csv('STM_actualizada.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clases correctas de la STM\n",
    "short_classes # Clases de la STM Actualizadas\n",
    "short_classes.to_csv('STM_clases_actualizadas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
